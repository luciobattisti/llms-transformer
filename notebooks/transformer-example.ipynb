{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f82032ac",
   "metadata": {},
   "source": [
    "# Disclaimer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f692b",
   "metadata": {},
   "source": [
    "The present notebook is largely based on this excellent tutorial:  \n",
    "https://www.tensorflow.org/text/tutorials/transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e3fb6f",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8849920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 10:20:38.391304: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-26 10:20:39.615341: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-26 10:20:39.617906: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-26 10:20:49.994589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e3fd36",
   "metadata": {},
   "source": [
    "# Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bbf85e",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edc05fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en',\n",
    "                               with_info=True,\n",
    "                               as_supervised=True)\n",
    "\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1aa04db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 10:21:08.517964: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_3' with dtype int64 and shape [1]\n",
      "\t [[{{node Placeholder/_3}}]]\n",
      "2023-06-26 10:21:08.518979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype string and shape [1]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Examples in Portuguese:\n",
      "e quando melhoramos a procura , tiramos a única vantagem da impressão , que é a serendipidade .\n",
      "mas e se estes fatores fossem ativos ?\n",
      "mas eles não tinham a curiosidade de me testar .\n",
      "\n",
      "> Examples in English:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 10:21:08.807202: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "  print('> Examples in Portuguese:')\n",
    "  for pt in pt_examples.numpy():\n",
    "    print(pt.decode('utf-8'))\n",
    "  print()\n",
    "\n",
    "  print('> Examples in English:')\n",
    "  for en in en_examples.numpy():\n",
    "    print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8bf862",
   "metadata": {},
   "source": [
    "## Setup the tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0a8f6",
   "metadata": {},
   "source": [
    "Now that you have loaded the dataset, you need to tokenize the text, so that each element is represented as a token or token ID (a numeric representation).  \n",
    "\n",
    "This tutorial uses the tokenizers built in the [subword tokenizer tutorial](https://www.tensorflow.org/text/guide/subwords_tokenizer). That tutorial optimizes two text.BertTokenizer objects (one for English, one for Portuguese) for this dataset and exports them in a TensorFlow saved_model format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d964a629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68afa4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469af067",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28660d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['detokenize',\n",
       " 'get_reserved_tokens',\n",
       " 'get_vocab_path',\n",
       " 'get_vocab_size',\n",
       " 'lookup',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'vocab']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in dir(tokenizers.en) if not item.startswith('_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5d547b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a batch of strings:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n't test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "print('> This is a batch of strings:')\n",
    "for en in en_examples.numpy():\n",
    "  print(en.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6f66a",
   "metadata": {},
   "source": [
    "The tokenize method converts a batch of strings to a padded-batch of token IDs. This method splits punctuation, lowercases and unicode-normalizes the input before tokenizing. That standardization is not visible here because the input data is already standardized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f521568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is a padded-batch of token IDs:\n",
      "[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n",
      "[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n",
      "[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "print('> This is a padded-batch of token IDs:')\n",
    "for row in encoded.to_list():\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91675335",
   "metadata": {},
   "source": [
    "The detokenize method attempts to convert these token IDs back to human-readable text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a65e37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 10:21:10.602525: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tokenized' with dtype int64 and shape [?]\n",
      "\t [[{{node tokenized}}]]\n",
      "2023-06-26 10:21:10.602687: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tokenized_1' with dtype int64 and shape [4]\n",
      "\t [[{{node tokenized_1}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is human-readable text:\n",
      "and when you improve searchability , you actually take away the one advantage of print , which is serendipity .\n",
      "but what if it were active ?\n",
      "but they did n ' t test for curiosity .\n"
     ]
    }
   ],
   "source": [
    "round_trip = tokenizers.en.detokenize(encoded)\n",
    "\n",
    "print('> This is human-readable text:')\n",
    "for line in round_trip.numpy():\n",
    "  print(line.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c16b6c",
   "metadata": {},
   "source": [
    "The lower level lookup method converts from token-IDs to token text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "082a4581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> This is the text split into tokens:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'[START]', b'and', b'when', b'you', b'improve', b'search', b'##ability',\n",
       "  b',', b'you', b'actually', b'take', b'away', b'the', b'one', b'advantage',\n",
       "  b'of', b'print', b',', b'which', b'is', b's', b'##ere', b'##nd', b'##ip',\n",
       "  b'##ity', b'.', b'[END]']                                                 ,\n",
       " [b'[START]', b'but', b'what', b'if', b'it', b'were', b'active', b'?',\n",
       "  b'[END]']                                                           ,\n",
       " [b'[START]', b'but', b'they', b'did', b'n', b\"'\", b't', b'test', b'for',\n",
       "  b'curiosity', b'.', b'[END]']                                          ]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('> This is the text split into tokens:')\n",
    "tokens = tokenizers.en.lookup(encoded)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481219a7",
   "metadata": {},
   "source": [
    "The output demonstrates the \"subword\" aspect of the subword tokenization.\n",
    "\n",
    "For example, the word 'searchability' is decomposed into 'search' and '##ability', and the word 'serendipity' into 's', '##ere', '##nd', '##ip' and '##ity'.\n",
    "\n",
    "Note that the tokenized text includes '[START]' and '[END]' tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b792b21",
   "metadata": {},
   "source": [
    "## Setup data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a07bee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=128\n",
    "def prepare_batch(pt, en):\n",
    "    pt = tokenizers.pt.tokenize(pt)      # Output is ragged.\n",
    "    pt = pt[:, :MAX_TOKENS]    # Trim to MAX_TOKENS.\n",
    "    pt = pt.to_tensor()  # Convert to 0-padded dense Tensor\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    en = en[:, :(MAX_TOKENS+1)]\n",
    "    en_inputs = en[:, :-1].to_tensor()  # Drop the [END] tokens\n",
    "    en_labels = en[:, 1:].to_tensor()   # Drop the [START] tokens\n",
    "\n",
    "    return (pt, en_inputs), en_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2813b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59291d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_batch, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6a6513",
   "metadata": {},
   "source": [
    "### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81bc517e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and validation set batches.\n",
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0370c",
   "metadata": {},
   "source": [
    "The resulting `tf.data.Dataset` objects are setup for training with Keras.\n",
    "Keras `Model.fit` training expects `(inputs, labels)` pairs.\n",
    "The `inputs` are pairs of tokenized Portuguese and English sequences, `(pt, en)`.\n",
    "The `labels` are the same English sequences shifted by 1.\n",
    "This shift is so that at each location input `en` sequence, the `label` in the next token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d8ef5",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th>Inputs at the bottom, labels at the top.</th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/Transformer-1layer-words.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ed886bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 10:21:11.527385: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_32' with dtype int64\n",
      "\t [[{{node Placeholder/_32}}]]\n",
      "2023-06-26 10:21:11.528454: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_33' with dtype int64\n",
      "\t [[{{node Placeholder/_33}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 67)\n",
      "(64, 72)\n",
      "(64, 72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 10:21:12.777472: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for (pt, en), en_labels in train_batches.take(1):\n",
    "  break\n",
    "\n",
    "print(pt.shape)\n",
    "print(en.shape)\n",
    "print(en_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9deb0138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([   2   78  110   89 2481   13  120   74  116 4755], shape=(10,), dtype=int64)\n",
      "tf.Tensor([  78  110   89 2481   13  120   74  116 4755 3134], shape=(10,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "print(en[0][:10])\n",
    "print(en_labels[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddf89f9",
   "metadata": {},
   "source": [
    "# Define the components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2416fe",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The original Transformer diagram</th>\n",
    "  <th colspan=1>A representation of a 4-layer Transformer</th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=400 src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
    "  </td>\n",
    "  <td>\n",
    "   <img width=307 src=\"https://www.tensorflow.org/images/tutorials/transformer/Transformer-4layer-compact.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc17e63",
   "metadata": {},
   "source": [
    "## The Embedding and Positional Encoding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d690e6",
   "metadata": {},
   "source": [
    "The inputs to both the encoder and decoder use the same embedding and positional encoding logic. \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The embedding and positional encoding layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/PositionalEmbedding.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9247f24a",
   "metadata": {},
   "source": [
    "Given a sequence of tokens, both the input tokens (Portuguese) and target tokens (English) have to be converted to vectors using a `tf.keras.layers.Embedding` layer.\n",
    "\n",
    "The attention layers used throughout the model see their input as a set of vectors, with no order. Since the model doesn't contain any recurrent or convolutional layers. It needs some way to identify word order, otherwise it would see the input sequence as a [bag of words](https://developers.google.com/machine-learning/glossary#bag-of-words) instance, `how are you`, `how you are`, `you how are`, and so on, are indistinguishable.\n",
    "\n",
    "A Transformer adds a \"Positional Encoding\" to the embedding vectors. It uses a set of sines and cosines at different frequencies (across the sequence). By definition nearby elements will have similar position encodings.\n",
    "\n",
    "The original paper uses the following formula for calculating the positional encoding:\n",
    "\n",
    "$$\\Large{PE_{(pos, 2i)} = \\sin(pos / 10000^{2i / d_{model}})} $$\n",
    "$$\\Large{PE_{(pos, 2i+1)} = \\cos(pos / 10000^{2i / d_{model}})} $$\n",
    "\n",
    "The position encoding function is a stack of sines and cosines that vibrate at different frequencies depending on their location along the depth of the embedding vector. They vibrate across the position axis.\n",
    "\n",
    "Additional resources:\n",
    "* https://medium.com/@corymaklin/transformers-explained-610b2f749f43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f71136",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13c2387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "  depth = depth/2\n",
    "\n",
    "  positions = np.arange(length)[:, np.newaxis]     # (seq, 1)\n",
    "  depths = np.arange(depth)[np.newaxis, :]/depth   # (1, depth)\n",
    "  \n",
    "  angle_rates = 1 / (10000**depths)         # (1, depth)\n",
    "  angle_rads = positions * angle_rates      # (pos, depth)\n",
    "\n",
    "  pos_encoding = np.concatenate(\n",
    "      [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "      axis=-1) \n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f3dcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "  def __init__(self, vocab_size, d_model):\n",
    "    super().__init__()\n",
    "    self.d_model = d_model # This is the size of the embedded vector\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero=True) \n",
    "    self.pos_encoding = positional_encoding(length=2048, depth=d_model)\n",
    "\n",
    "  def compute_mask(self, *args, **kwargs):\n",
    "    return self.embedding.compute_mask(*args, **kwargs)\n",
    "\n",
    "  def call(self, x):\n",
    "    length = tf.shape(x)[1]\n",
    "    x = self.embedding(x)\n",
    "    # This factor sets the relative scale of the embedding and positonal_encoding.\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x = x + self.pos_encoding[tf.newaxis, :length, :]\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04437d5",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eb0ae33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2048, 512), dtype=float32, numpy=\n",
       "array([[ 0.        ,  0.        ,  0.        , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.84147096,  0.8218562 ,  0.8019618 , ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       [ 0.9092974 ,  0.9364147 ,  0.95814437, ...,  1.        ,\n",
       "         1.        ,  1.        ],\n",
       "       ...,\n",
       "       [ 0.17589758, -0.18608274, -0.7070546 , ...,  0.9741639 ,\n",
       "         0.97595036,  0.97761387],\n",
       "       [-0.7333133 ,  0.7014913 ,  0.1447375 , ...,  0.9741387 ,\n",
       "         0.97592694,  0.97759205],\n",
       "       [-0.9683193 ,  0.98535496,  0.8799798 , ...,  0.9741135 ,\n",
       "         0.9759035 ,  0.9775702 ]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positional_encoding(2048, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b6c3509",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_pt = PositionalEmbedding(vocab_size=tokenizers.pt.get_vocab_size(), d_model=512)\n",
    "embed_en = PositionalEmbedding(vocab_size=tokenizers.en.get_vocab_size(), d_model=512)\n",
    "\n",
    "pt_emb = embed_pt(pt)\n",
    "en_emb = embed_en(en)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea55ed19",
   "metadata": {},
   "source": [
    "## Add and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c513b8",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=2>Add and normalize</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Add+Norm.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c229fb",
   "metadata": {},
   "source": [
    "These \"Add & Norm\" blocks are scattered throughout the model. Each one joins a residual connection and runs the result through a `LayerNormalization` layer.\n",
    "\n",
    "The residual \"Add & Norm\" blocks are included so that training is efficient. The residual connection provides a direct path for the gradient (and ensures that vectors are **updated** by the attention layers instead of **replaced**), while the normalization maintains a reasonable scale for the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946c2537",
   "metadata": {},
   "source": [
    "## Base Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddf9cb2",
   "metadata": {},
   "source": [
    "Attention layers are used throughout the model. These are all identical except for how the attention is configured. Each one contains a `layers.MultiHeadAttention`, a `layers.LayerNormalization` and a `layers.Add`. \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=2>The base attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/BaseAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd58e2f",
   "metadata": {},
   "source": [
    "### Attention Refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95a26a6",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The base attention layer</th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=430 src=\"https://www.tensorflow.org/images/tutorials/transformer/BaseAttention-new.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e347f8f",
   "metadata": {},
   "source": [
    "There are two inputs:\n",
    "\n",
    "1. The query sequence; the sequence being processed; the sequence doing the attending (bottom).\n",
    "2. The context sequence; the sequence being attended to (left).\n",
    "\n",
    "The output has the same shape as the query-sequence.\n",
    "\n",
    "The common comparison is that this operation is like a dictionary lookup.\n",
    "A **fuzzy**, **differentiable**, **vectorized** dictionary lookup.\n",
    "\n",
    "Here's a regular python dictionary, with 3 keys and 3 values being passed a single query.\n",
    "\n",
    "```\n",
    "d = {'color': 'blue', 'age': 22, 'type': 'pickup'}\n",
    "result = d['color']\n",
    "```\n",
    "\n",
    "- The `query`s is what you're trying to find.\n",
    "- The `key`s what sort of information the dictionary has.\n",
    "- The `value` is that information.\n",
    "\n",
    "When you look up a `query` in a regular dictionary, the dictionary finds the matching `key`, and returns its associated `value`.\n",
    "The `query` either has a matching `key` or it doesn't.\n",
    "You can imagine a **fuzzy** dictionary where the keys don't have to match perfectly.\n",
    "If you looked up `d[\"species\"]` in the dictionary above, maybe you'd want it to return `\"pickup\"` since that's the best match for the query.\n",
    "\n",
    "An attention layer does a fuzzy lookup like this, but it's not just looking for the best key.\n",
    "It combines the `values` based on how well the `query` matches each `key`.\n",
    "\n",
    "How does that work? In an attention layer the `query`, `key`, and `value` are each vectors.\n",
    "Instead of doing a hash lookup the attention layer combines the `query` and `key` vectors to determine how well they match, the \"attention score\".\n",
    "The layer returns the average across all the `values`, weighted by the \"attention scores\".\n",
    "\n",
    "Each location the query-sequence provides a `query` vector.\n",
    "The context sequence acts as the dictionary. At each location in the context sequence provides a `key` and `value` vector.\n",
    "The input vectors are not used directly, the `layers.MultiHeadAttention` layer includes `layers.Dense` layers to project the input vectors before using them.\n",
    "\n",
    "Additional resources:\n",
    "* https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a\n",
    "* https://lih-verma.medium.com/query-key-and-value-in-attention-mechanism-3c3c6a2d4085\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7ec45",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "867ea4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAttention(tf.keras.layers.Layer):\n",
    "  def __init__(self, **kwargs):\n",
    "    super().__init__()\n",
    "    self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
    "    self.layernorm = tf.keras.layers.LayerNormalization()\n",
    "    self.add = tf.keras.layers.Add()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a7ebf",
   "metadata": {},
   "source": [
    "## Cross Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d735795",
   "metadata": {},
   "source": [
    "The cross-attention layer connects the encoder and decoder. \n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The cross attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/CrossAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6eab9f7",
   "metadata": {},
   "source": [
    "Each query has access to the key/value context but no information is passed between queries. The output length is the length of the `query` sequence, and not the length of the context `key/value` sequence.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th>The cross attention layer</th>\n",
    "</tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=430 src=\"https://www.tensorflow.org/images/tutorials/transformer/CrossAttention-new-full.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e375b92",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e91d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(BaseAttention):\n",
    "  def call(self, x, context):\n",
    "    attn_output, attn_scores = self.mha(\n",
    "        query=x,\n",
    "        key=context,\n",
    "        value=context,\n",
    "        return_attention_scores=True)\n",
    "   \n",
    "    # Cache the attention scores for plotting later.\n",
    "    self.last_attn_scores = attn_scores\n",
    "\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c27c027",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78013753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 67, 512)\n",
      "(64, 72, 512)\n",
      "(64, 72, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_ca = CrossAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(pt_emb.shape)\n",
    "print(en_emb.shape)\n",
    "print(sample_ca(en_emb, pt_emb).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd380b5-3231-46ab-99a8-eb409ea730a1",
   "metadata": {},
   "source": [
    "## Global Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75441cf7-f944-4a9f-890d-9328b72a6008",
   "metadata": {},
   "source": [
    "This layer is responsible for processin the context sequence\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The global self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/SelfAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd79b6d-97a6-4196-bbe0-7041031bc5bc",
   "metadata": {},
   "source": [
    "Query and context are the same tensors. Hence the name `self` attention\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The global self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=330 src=\"https://www.tensorflow.org/images/tutorials/transformer/SelfAttention-new-full.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fd9aa8-5f4d-464f-a71d-421ee35e99ed",
   "metadata": {},
   "source": [
    "Before Transformers and self attention, models commonly used RNNs or CNNs to do this task.\n",
    "\n",
    "RNNs and CNNs have their limitations.\n",
    "\n",
    "- The RNN allows information to flow all the way across the sequence, but it passes through many processing steps to get there (limiting gradient flow). These RNN steps have to be run sequentially and so the RNN is less able to take advantage of modern parallel devices.\n",
    "- In the CNN each location can be processed in parallel, but it only provides a limited receptive field. The receptive field only grows linearly with the number of CNN layers,  You need to stack a number of Convolution layers to transmit information across the sequence ([Wavenet](https://arxiv.org/abs/1609.03499) reduces this problem by using dilated convolutions).\n",
    "\n",
    "The global self attention layer on the other hand lets every sequence element directly access every other sequence element, with only a few operations, and all the outputs can be computed in parallel. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804cea4a-8173-4d14-9aaf-1cd3094cdfc5",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef3df60d-64ed-448d-9c0f-a2b3dcf243cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdde804-1b98-4581-90f2-c670b02e9a82",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "56541f2b-e7db-40bb-a44c-a8e63f381dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 67, 512)\n",
      "(64, 67, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_gsa = GlobalSelfAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(pt_emb.shape)\n",
    "print(sample_gsa(pt_emb).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32730afb-da2f-4a08-a050-919696569f06",
   "metadata": {},
   "source": [
    "## Casual Self Attention Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f787d2-b9af-4296-a2c2-b59cf8cb6187",
   "metadata": {},
   "source": [
    "This layer is similar to global self attention, however it implements a causal approach for sequence processing\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The causal self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/CausalSelfAttention.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df662bc-79c6-46be-880a-a7f9359e0b67",
   "metadata": {},
   "source": [
    "Like the [text generation tutorial](https://www.tensorflow.org/text/tutorials/text_generation), and the [NMT with attention](https://www.tensorflow.org/text/tutorials/nmt_with_attention) tutorial, Transformers are an \"autoregressive\" model: They generate the text one token at a time and feed that output back to the input. To make this _efficient_, these models ensure that the output for each sequence element only depends on the previous sequence elements; the models are \"causal\".\n",
    "\n",
    "To build a causal self attention layer, you need to use an appropriate mask when computing the attention scores and summing the attention `value`s.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The causal self attention layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img width=330 src=\"https://www.tensorflow.org/images/tutorials/transformer/CausalSelfAttention-new-full.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968efc74-0706-4d47-a191-807049658dea",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3b43714-3948-4592-be66-b651734aea2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CausalSelfAttention(BaseAttention):\n",
    "  def call(self, x):\n",
    "    attn_output = self.mha(\n",
    "        query=x,\n",
    "        value=x,\n",
    "        key=x,\n",
    "        use_causal_mask = True)\n",
    "    x = self.add([x, attn_output])\n",
    "    x = self.layernorm(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b69ed0-e970-40de-8354-bd2bbc48d0cc",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7926f2a4-6eb3-45bd-bdb6-d7b55c2af04f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 72, 512)\n",
      "(64, 72, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_csa = CausalSelfAttention(num_heads=2, key_dim=512)\n",
    "\n",
    "print(en_emb.shape)\n",
    "print(sample_csa(en_emb).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb894eee-7ad1-468e-9264-8c80866ce29e",
   "metadata": {},
   "source": [
    "## Feed Forward Network layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c4dc62-ace8-4a5b-8967-314ee632a941",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The feed forward network</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/FeedForward.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae4e538-d045-4b44-a5d5-5d57a8225e6a",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61294a08-f303-4f92-aaf7-60772d1b58f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "  def __init__(self, d_model, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),\n",
    "      tf.keras.layers.Dense(d_model),\n",
    "      tf.keras.layers.Dropout(dropout_rate)\n",
    "    ])\n",
    "    self.add = tf.keras.layers.Add()\n",
    "    self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.add([x, self.seq(x)])\n",
    "    x = self.layer_norm(x) \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702e1201-64a1-455e-b53b-4e84bba8b40e",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d75f0f18-d161-4d71-8d97-7cc10a95e680",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 72, 512)\n",
      "(64, 72, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_ffn = FeedForward(512, 2048)\n",
    "\n",
    "print(en_emb.shape)\n",
    "print(sample_ffn(en_emb).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7027a-870a-4f9b-b6a7-ee7f85d8c67f",
   "metadata": {},
   "source": [
    "## The Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5ef675-94c0-454a-8b62-59b32eb0a8c5",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The encoder</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Encoder.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34715f8c-d489-42ba-937e-24d69e82f278",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fde89616-625b-4a0a-916e-8b0e713fed44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,*, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.self_attention = GlobalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x):\n",
    "    x = self.self_attention(x)\n",
    "    x = self.ffn(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57e4f8c9-ac8f-4ef9-8e7b-6052ca1dae2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads,\n",
    "               dff, vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(\n",
    "        vocab_size=vocab_size, d_model=d_model)\n",
    "\n",
    "    self.enc_layers = [\n",
    "        EncoderLayer(d_model=d_model,\n",
    "                     num_heads=num_heads,\n",
    "                     dff=dff,\n",
    "                     dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "  def call(self, x):\n",
    "    # `x` is token-IDs shape: (batch, seq_len)\n",
    "    x = self.pos_embedding(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    \n",
    "    # Add dropout.\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x = self.enc_layers[i](x)\n",
    "\n",
    "    return x  # Shape `(batch_size, seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb24b07-1bd0-47de-8cb7-1977b265f8e4",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b88bff4-3b91-49bc-9123-75b1d53f83d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 67)\n",
      "(64, 67, 512)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the encoder.\n",
    "sample_encoder = Encoder(num_layers=4,\n",
    "                         d_model=512,\n",
    "                         num_heads=8,\n",
    "                         dff=2048,\n",
    "                         vocab_size=8500)\n",
    "\n",
    "sample_encoder_output = sample_encoder(pt, training=False)\n",
    "\n",
    "# Print the shape.\n",
    "print(pt.shape)\n",
    "print(sample_encoder_output.shape)  # Shape `(batch_size, input_seq_len, d_model)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117ff718-6d83-4869-80d6-3bb257a17b85",
   "metadata": {},
   "source": [
    "# The Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97af6d1-46db-4868-95ff-472669db6b53",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The embedding and positional encoding layer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/Decoder.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e73188-f7e0-4530-90f7-ee61f8703be4",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b6a87ba3-ec31-4ef8-aeba-5bc9b30872ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "  def __init__(self,\n",
    "               *,\n",
    "               d_model,\n",
    "               num_heads,\n",
    "               dff,\n",
    "               dropout_rate=0.1):\n",
    "    super(DecoderLayer, self).__init__()\n",
    "\n",
    "    self.causal_self_attention = CausalSelfAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "    \n",
    "    self.cross_attention = CrossAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=d_model,\n",
    "        dropout=dropout_rate)\n",
    "\n",
    "    self.ffn = FeedForward(d_model, dff)\n",
    "\n",
    "  def call(self, x, context):\n",
    "    x = self.causal_self_attention(x=x)\n",
    "    x = self.cross_attention(x=x, context=context)\n",
    "\n",
    "    # Cache the last attention scores for plotting later\n",
    "    self.last_attn_scores = self.cross_attention.last_attn_scores\n",
    "\n",
    "    x = self.ffn(x)  # Shape `(batch_size, seq_len, d_model)`.\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ca96eef-b87c-4b74-bb66-9824ffd1848e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff, vocab_size,\n",
    "               dropout_rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "\n",
    "    self.pos_embedding = PositionalEmbedding(vocab_size=vocab_size,\n",
    "                                             d_model=d_model)\n",
    "    self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "    self.dec_layers = [\n",
    "        DecoderLayer(d_model=d_model, num_heads=num_heads,\n",
    "                     dff=dff, dropout_rate=dropout_rate)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "    self.last_attn_scores = None\n",
    "\n",
    "  def call(self, x, context):\n",
    "    # `x` is token-IDs shape (batch, target_seq_len)\n",
    "    x = self.pos_embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "    x = self.dropout(x)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x  = self.dec_layers[i](x, context)\n",
    "\n",
    "    self.last_attn_scores = self.dec_layers[-1].last_attn_scores\n",
    "\n",
    "    # The shape of x is (batch_size, target_seq_len, d_model).\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d0665-797b-4409-a320-5f2f6c731678",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5dc53625-b0f8-4dda-b0f3-e6ef174d0a67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 72)\n",
      "(64, 67, 512)\n",
      "(64, 72, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=4,\n",
    "                         d_model=512,\n",
    "                         num_heads=8,\n",
    "                         dff=2048,\n",
    "                         vocab_size=8000)\n",
    "\n",
    "output = sample_decoder(\n",
    "    x=en,\n",
    "    context=pt_emb)\n",
    "\n",
    "# Print the shapes.\n",
    "print(en.shape)\n",
    "print(pt_emb.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb8cf82-223c-4709-8492-b249108f2051",
   "metadata": {},
   "source": [
    "# The Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919c3c02-6736-4098-8673-a4d2ad6b99cc",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "  <th colspan=1>The transformer</th>\n",
    "<tr>\n",
    "<tr>\n",
    "  <td>\n",
    "   <img src=\"https://www.tensorflow.org/images/tutorials/transformer/transformer.png\"/>\n",
    "  </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77831b8-ae19-4e5f-90e0-24124932be1f",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "131b3623-3f65-4ebe-a01c-23421968e38f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "  def __init__(self, *, num_layers, d_model, num_heads, dff,\n",
    "               input_vocab_size, target_vocab_size, dropout_rate=0.1):\n",
    "    super().__init__()\n",
    "    self.encoder = Encoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=input_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.decoder = Decoder(num_layers=num_layers, d_model=d_model,\n",
    "                           num_heads=num_heads, dff=dff,\n",
    "                           vocab_size=target_vocab_size,\n",
    "                           dropout_rate=dropout_rate)\n",
    "\n",
    "    self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # To use a Keras model with `.fit` you must pass all your inputs in the\n",
    "    # first argument.\n",
    "    context, x  = inputs\n",
    "\n",
    "    context = self.encoder(context)  # (batch_size, context_len, d_model)\n",
    "\n",
    "    x = self.decoder(x, context)  # (batch_size, target_len, d_model)\n",
    "\n",
    "    # Final linear layer output.\n",
    "    logits = self.final_layer(x)  # (batch_size, target_len, target_vocab_size)\n",
    "\n",
    "    try:\n",
    "      # Drop the keras mask, so it doesn't scale the losses/metrics.\n",
    "      # b/250038731\n",
    "      del logits._keras_mask\n",
    "    except AttributeError:\n",
    "      pass\n",
    "\n",
    "    # Return the final output and the attention weights.\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60653fe1-2f3b-48d0-89b7-db0a3a575eb1",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1d1f70ac-d25c-432a-abe4-0daebc34b278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c27466-e5b3-41f1-a913-64059cf2c70c",
   "metadata": {},
   "source": [
    "## Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b5206f5-b385-4cea-ac83-a2636b2237a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
    "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
    "    dropout_rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14133331-5b94-4386-b875-e7bf0926b9f2",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a083a035-379d-404c-857f-2b72d2585632",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 72)\n",
      "(64, 67)\n",
      "(64, 72, 7010)\n"
     ]
    }
   ],
   "source": [
    "output = transformer((pt, en))\n",
    "\n",
    "print(en.shape)\n",
    "print(pt.shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bfb62e70-a0bf-4859-8cf9-5394c0adcf6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 8, 72, 67)\n"
     ]
    }
   ],
   "source": [
    "attn_scores = transformer.decoder.dec_layers[-1].last_attn_scores\n",
    "print(attn_scores.shape)  # (batch, heads, target_seq, input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "172ee66d-135c-4349-a523-a3eca8f41f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_1 (Encoder)         multiple                  3632768   \n",
      "                                                                 \n",
      " decoder_1 (Decoder)         multiple                  5647104   \n",
      "                                                                 \n",
      " dense_34 (Dense)            multiple                  904290    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,184,162\n",
      "Trainable params: 10,184,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eba3ada-42b8-49f3-9a1c-43738eecf925",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933824d6-07dc-4cac-9875-81c4d6dd98f6",
   "metadata": {},
   "source": [
    "## Setup optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905f781c-5350-4d59-8f83-b8a21516f345",
   "metadata": {},
   "source": [
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the original Transformer [paper](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "$$\\Large{lrate = d_{model}^{-0.5} * \\min(step{\\_}num^{-0.5}, step{\\_}num \\cdot warmup{\\_}steps^{-1.5})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0312e1a-29e2-4d54-af72-120065b1a934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super().__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, dtype=tf.float32)\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6f51ac2-1b38-411e-9dc8-6e4d3a4d770d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7258100-52b3-47ac-9195-219b7312baa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlEAAAGwCAYAAACJjDBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABrNklEQVR4nO3deXxTVd4/8E/SNknXtKU06UZboOxlsUApguhQLYJIHUeB4RGG4RHHHy4IKsJAUQcHRB0VRdFxQR8XFkcZRUBr2VRKgdKy75S2LOnepPuSnN8fpVciBdqS9Dbp5/165dX25tyb72mAfLjn3HMVQggBIiIiImoRpdwFEBERETkihigiIiKiVmCIIiIiImoFhigiIiKiVmCIIiIiImoFhigiIiKiVmCIIiIiImoFV7kLcGYWiwUXL16Et7c3FAqF3OUQERFRMwghUFZWhuDgYCiV1z7fxBBlRxcvXkRYWJjcZRAREVEr5ObmIjQ09JrPM0TZkbe3N4CGN8HHx0fmaoiIiKg5TCYTwsLCpM/xa2GIsqPGITwfHx+GKCIiIgdzo6k4nFhORERE1AoMUUREREStwBBFRERE1AoMUUREREStwBBFRERE1AoMUUREREStwBBFRERE1AoMUUREREStwBBFRERE1AoMUUREREStIHuIWrlyJSIiIqDRaBAbG4s9e/Zct/369evRq1cvaDQaREdHY9OmTVbPCyGQlJSEoKAguLu7Iz4+HqdOnbJq89JLL2H48OHw8PCAr6/vdV+vqKgIoaGhUCgUKC0tbU0XiYiIyAnJGqLWrl2LOXPmYPHixdi/fz8GDBiAhIQE5OfnN9l+165dmDx5MmbMmIGMjAwkJiYiMTERhw8fltosX74cK1aswKpVq5CWlgZPT08kJCSgurpaalNbW4sHHngAjz766A1rnDFjBvr373/znSUiIiKnohBCCLlePDY2FkOGDMHbb78NALBYLAgLC8Pjjz+O55577qr2EydOREVFBTZu3ChtGzZsGAYOHIhVq1ZBCIHg4GDMnTsXTz/9NADAaDRCp9Nh9erVmDRpktXxVq9ejdmzZ1/zDNO7776LtWvXIikpCaNHj0ZJScl1z1zV1NSgpqZG+rnxLtBGo7HD34BYCAGzRcDVRfaTn0RERNdlMpmg1Wpv+Pkt2ydabW0t0tPTER8f/1sxSiXi4+ORmpra5D6pqalW7QEgISFBap+VlQWDwWDVRqvVIjY29prHvJajR4/ixRdfxKeffgqlsnm/pqVLl0Kr1UqPsLCwFr2mM3vsiwwMW5qC/LLqGzcmIiJyALKFqMLCQpjNZuh0OqvtOp0OBoOhyX0MBsN12zd+bckxm1JTU4PJkyfjlVdeQZcuXZq93/z582E0GqVHbm5us/d1ZkIIfH/oEgrLa/HhL1lyl0NERGQTrnIX0B7Nnz8fvXv3xv/8z/+0aD+1Wg21Wm2nqhxXftlvQ5wnDWUyVkJERGQ7sp2JCggIgIuLC/Ly8qy25+XlQa/XN7mPXq+/bvvGry05ZlO2bt2K9evXw9XVFa6urhg9erRU8+LFi5t9HGqQU1wpfb/3XAlq6y0yVkNERGQbsoUolUqFmJgYpKSkSNssFgtSUlIQFxfX5D5xcXFW7QEgOTlZah8ZGQm9Xm/VxmQyIS0t7ZrHbMp//vMfHDhwAJmZmcjMzMQHH3wAAPj5558xa9asZh+HGuQU/RaiymvqsT+nRMZqiIiIbEPW4bw5c+Zg2rRpGDx4MIYOHYo33ngDFRUVmD59OgBg6tSpCAkJwdKlSwEATz75JEaNGoXXXnsN48aNw5o1a7Bv3z68//77AACFQoHZs2djyZIliIqKQmRkJBYtWoTg4GAkJiZKr5uTk4Pi4mLk5OTAbDYjMzMTANC9e3d4eXmhW7duVnUWFhYCAHr37n3DdaXoatlXnIkCgB0nCzCsayeZqiEiIrINWUPUxIkTUVBQgKSkJBgMBgwcOBBbtmyRJobn5ORYXRk3fPhwfPHFF1i4cCEWLFiAqKgobNiwAf369ZPaPPvss6ioqMDMmTNRWlqKESNGYMuWLdBoNFKbpKQkfPLJJ9LPgwYNAgBs27YNt99+u5173fHkXg5RPXXeOJFXhh0nCjBvTC+ZqyIiIro5sq4T5eyau86Es7v/3V1Izy7BixP6YvG3RyAEsGfBaAT6aG68MxERURtr9+tEUceRfXlO1KAwP0SHaAEAO08VylkSERHRTWOIIruqrK1HYXnDEgdd/D0wqkdnAA3zooiIiBwZQxTZVW5xFQBA6+4GrYebFKJ+PlWAejOXOiAiIsfFEEV2lV1UAaDhLBQADAzzha+HG0or65CezaUOiIjIcTFEkV01LrTZGKJcXZT4Q89AAMBPx/KuuR8REVF7xxBFdiWFqE4e0rY7+zQsYZF8NA+8OJSIiBwVQxTZ1e/PRAHAyB6doXJR4lxRJc4UlMtVGhER0U1hiCK7aipEealdEdetYcXy5KP5stRFRER0sxiiyG7MFoHzl6/OuzJEAUD85SE9zosiIiJHxRBFdpNnqkat2QJXpQJBWuvVyeN7N0wu359TIq0jRURE5EgYoshuGofyQvzc4epi/UctSOuO6BAthAC2HuOQHhEROR6GKLKbnKKr50NdKb53w5Dej0cNbVYTERGRrTBEkd00Nan8Sgn9GkLUzlOFKKuua7O6iIiIbIEhiuzmRiGqp84bXTt7orbeghQO6RERkYNhiCK7yb4cosI7NR2iFAoFxkUHAQC+P3SpzeoiIiKyBYYospvcyyEq7BpnogBgXP+GELXjZAGH9IiIyKEwRJFdlFXXobiiFsC1h/MADukREZHjYogiu2icD+XvqYK3xu2a7TikR0REjoohiuyiOUN5jcZGc0iPiIgcD0MU2UXjmajwZoSoXnpvdA1oGNLbepxDekRE5BgYosgusm+w0OaVFAqFNMH828yLdq2LiIjIVhiiyC5utEbU7907IBhAw5BeEe+lR0REDoAhiuxCClHXWCPq96J03ugX4oN6i+AEcyIicggMUWRz9WYLLpRUAWj+mSgAuG9QKADg6/0X7FIXERGRLTFEkc1dMlaj3iKgclFC56Np9n73DgiGi1KBzNxSnC0ot2OFREREN48himyucSgv1N8dLkpFs/fr7K3GiO4BAIANnGBORETtHEMU2VxLJ5Vf6Y+3hAAANmRcgBDCpnURERHZEkMU2dzNhKg7++jgoXJBTnEl9ueU2Lo0IiIim2GIIpvLacEaUb/noXLFmH56AMBX6ZxgTkRE7RdDFNnczZyJAoA/xTRcpffdgYuorK23WV1ERES2xBBFNifd8qWTZ6v2HxbZCeGdPFBeU4/vD3LNKCIiap8YosimjJV1MFY13EQ4zN+9VcdQKhV4cHAYAGDt3lyb1UZERGRLDFFkU41noQK81PBQubb6OH+KCYWLUoF92SU4nV9mq/KIiIhshiGKbOq3obzWzYdqpPPR4I6egQB4NoqIiNonhiiyqeziCgCtn1R+pUlDGob0/rP/AmrrLTd9PCIiIltiiCKbyr18JirMBiHq9p6dofNRo7iiFj8dy7vp4xEREdkSQxTZVPblNaLCbRCiXF2UeCCm4WzUZ7uzb/p4REREtiR7iFq5ciUiIiKg0WgQGxuLPXv2XLf9+vXr0atXL2g0GkRHR2PTpk1WzwshkJSUhKCgILi7uyM+Ph6nTp2yavPSSy9h+PDh8PDwgK+v71WvceDAAUyePBlhYWFwd3dH79698eabb950XzsCaY2om5wT1WjS0DAoFcCuM0U4lccJ5kRE1H7IGqLWrl2LOXPmYPHixdi/fz8GDBiAhIQE5OfnN9l+165dmDx5MmbMmIGMjAwkJiYiMTERhw8fltosX74cK1aswKpVq5CWlgZPT08kJCSgurpaalNbW4sHHngAjz76aJOvk56ejsDAQHz22Wc4cuQI/v73v2P+/Pl4++23bfsLcDJ1ZgsullYBsM2cKAAI9fPAnX10AIBPU3k2ioiI2g+FkPEur7GxsRgyZIgUTiwWC8LCwvD444/jueeeu6r9xIkTUVFRgY0bN0rbhg0bhoEDB2LVqlUQQiA4OBhz587F008/DQAwGo3Q6XRYvXo1Jk2aZHW81atXY/bs2SgtLb1hrbNmzcKxY8ewdevWa7apqalBTU2N9LPJZEJYWBiMRiN8fHxu+BqO7lxhBW5/dTvUrkoc/8cYKBQKmxx31+lC/PmDNHioXLB7wWj4aNxsclwiIqKmmEwmaLXaG35+y3Ymqra2Funp6YiPj/+tGKUS8fHxSE1NbXKf1NRUq/YAkJCQILXPysqCwWCwaqPVahEbG3vNYzaX0WiEv7//ddssXboUWq1WeoSFhd3UazqaK2/3YqsABQBx3TohKtALlbVm/Cf9vM2OS0REdDNkC1GFhYUwm83Q6XRW23U6HQwGQ5P7GAyG67Zv/NqSYzbHrl27sHbtWsycOfO67ebPnw+j0Sg9cnM71vpGN3vPvGtRKBSYOjwCAPB/qdmwWGQ7eUpERCSRfWJ5e3f48GFMmDABixcvxl133XXdtmq1Gj4+PlaPjsTWk8qv9MdBIfBWu+JsYQV+Pl1o8+MTERG1lGwhKiAgAC4uLsjLs17/Jy8vD3q9vsl99Hr9dds3fm3JMa/n6NGjGD16NGbOnImFCxe2eP+OJqfIPmeiAMBT7Yr7Y0IBAKt/zbL58YmIiFpKthClUqkQExODlJQUaZvFYkFKSgri4uKa3CcuLs6qPQAkJydL7SMjI6HX663amEwmpKWlXfOY13LkyBHccccdmDZtGl566aUW7dtR2eqWL9cybXgEFApg24kCLndARESyk3U4b86cOfj3v/+NTz75BMeOHcOjjz6KiooKTJ8+HQAwdepUzJ8/X2r/5JNPYsuWLXjttddw/PhxPP/889i3bx8ee+wxAA1zZ2bPno0lS5bg22+/xaFDhzB16lQEBwcjMTFROk5OTg4yMzORk5MDs9mMzMxMZGZmory8HEDDEN4dd9yBu+66C3PmzIHBYIDBYEBBQUHb/XIcjBDCbnOiGkUGeOKuy8sd/Pvns3Z5DSIiouZylfPFJ06ciIKCAiQlJcFgMGDgwIHYsmWLNDE8JycHSuVvOW/48OH44osvsHDhQixYsABRUVHYsGED+vXrJ7V59tlnUVFRgZkzZ6K0tBQjRozAli1boNFopDZJSUn45JNPpJ8HDRoEANi2bRtuv/12fPXVVygoKMBnn32Gzz77TGoXHh6Oc+fO2evX4dBKKutQXlMPoGFtJ3uZeVs3/HAkDxsyLuLpu3oi0Edz452IiIjsQNZ1opxdc9eZcAaZuaVIXPkr9D4a7F4w2q6v9ad3d2Ffdgkevb0b5o3pZdfXIiKijqfdrxNFziW7qAKA/YbyrjTztq4AGu6n13j2i4iIqK0xRJFN5F6eDxXWBiEqvrcOXTt7oqy6Hmv25Nj99YiIiJrCEEU2kV1k3yvzrqRUKjBzZMPZqI9+yUKd2WL31yQiIvo9hiiyCXtfmfd7iYNC0NlbjYvGanyz/0KbvCYREdGVGKLIJtpyOA8ANG4ueOTy3Ki3t51GPc9GERFRG2OIoptWU2/GJVM1gLYZzmv059gu6OSpQk5xJf6bebHNXpeIiAhgiCIbOF9SBSEAD5ULOnmq2ux1PVSueJhno4iISCYMUXTTrpwPpVAo2vS1HxoWDj8PN2QVVmDjwUtt+tpERNSxMUTRTbPnjYdvxFPtiv+9fKXeW1tPwWzh2rFERNQ2GKLoprX1lXm/NzUuHFp3N5wpqMDGg5wbRUREbYMhim6aFKLacFL5lbw1bnh4ZCQA4PXkk1w3ioiI2gRDFN00OYfzGk2/NRIBXiqcK6rEun25stVBREQdB0MU3RQhhOzDeUDD3KjH/xAFAHjzp1OoqjXLVgsREXUMDFF0UwrLa1FVZ4ZCAYT6yReiAGDy0C4I9XNHflkNVu86J2stRETk/Bii6KbkFFcAAIK17lC5yvvHSeWqxJw7ewAA3t1+GsbKOlnrISIi58YQRTclR7rdi7vMlTSYMDAEPXXeMFXX490dZ+Quh4iInBhDFN2U7MuTysP9PWWupIGLUoFnEnoCAD7+NQsXSqtkroiIiJwVQxTdFLmXN2jK6N6BiI30R029BS9vPi53OURE5KQYouim5ErDee0nRCkUCiy6pw8UCuDbAxeRnl0sd0lEROSEGKLopvw2nNd+QhQA9AvR4sGYMADAi98dhYW3gyEiIhtjiKJWq6o1I7+sBoC8a0Rdy9yEHvBUueDAeSM2ZF6QuxwiInIyDFHUaudLGs5Ceatd4evhJnM1Vwv01mDWH7oDAF7echyVtfUyV0RERM6EIYparXEor0snDygUCpmradpfb41EmL878kw1eHvrabnLISIiJ8IQRa3WHm73ciMaNxcsHNcHAPDvn8/idH6ZzBUREZGzYIiiVnOEEAUAd/XR4Q+9AlFnFli44TCE4CRzIiK6eQxR1GrtcY2opigUCrxwb19o3JTYfbaYk8yJiMgmGKKo1RzlTBTQsI7V43+IAgC89P0x3lePiIhuGkMUtYrFIqSFNtvLLV9u5OGRXdGtsycKy2vxyo9cyZyIiG4OQxS1Sn5ZDWrqLXBRKhDkq5G7nGZRuSrxjwn9AACfp+UgPbtE5oqIiMiRMURRqzQO5QX7auDm4jh/jIZ3D8AfbwmBEMCzXx1AdZ1Z7pKIiMhBOc6nH7UrOQ42lHelpHv6IMBLjTMFFViRckrucoiIyEExRFGr5BRVAGhfNx5uLl8PFZYkNgzrvbfzLA6dN8pcEREROSKGKGoVR7oyrylj+ulxT/8gmC0Cz3x1ALX1FrlLIiIiB8MQRa2S3Tic187XiLqeF+7tC39PFY4byvDOdt4ShoiIWoYhilol18HPRAFAJy81nr+3LwDg7a2ncfB8qbwFERGRQ2GIoharqKlHYXktAMecE3Wl8f2DMC46CPUWgdlrMlFZWy93SURE5CAYoqjFGudD+Xq4QevuJnM1N0ehUOCl+/pB76PB2cIKvPT9MblLIiIiByF7iFq5ciUiIiKg0WgQGxuLPXv2XLf9+vXr0atXL2g0GkRHR2PTpk1WzwshkJSUhKCgILi7uyM+Ph6nTllfxv7SSy9h+PDh8PDwgK+vb5Ovk5OTg3HjxsHDwwOBgYF45plnUF/PsxSA408q/z1fDxVee3AAgIZFOFOO5clcEREROQJZQ9TatWsxZ84cLF68GPv378eAAQOQkJCA/Pz8Jtvv2rULkydPxowZM5CRkYHExEQkJibi8OHDUpvly5djxYoVWLVqFdLS0uDp6YmEhARUV1dLbWpra/HAAw/g0UcfbfJ1zGYzxo0bh9raWuzatQuffPIJVq9ejaSkJNv+AhxU43woRx/Ku9Kt3QPwvyMiAQDPfnUQBWU1MldERETtnpDR0KFDxaxZs6SfzWazCA4OFkuXLm2y/YMPPijGjRtntS02NlY88sgjQgghLBaL0Ov14pVXXpGeLy0tFWq1Wnz55ZdXHe/jjz8WWq32qu2bNm0SSqVSGAwGadu7774rfHx8RE1NTbP7ZzQaBQBhNBqbvY8jWPjNIRE+b6N4efMxuUuxqaraepHw+g4RPm+j+MtHacJstshdEhERyaC5n9+ynYmqra1Feno64uPjpW1KpRLx8fFITU1tcp/U1FSr9gCQkJAgtc/KyoLBYLBqo9VqERsbe81jXut1oqOjodPprF7HZDLhyJEj19yvpqYGJpPJ6uGMnG04r5HGzQVvThoElasS204U4N8/n5W7JCIiasdkC1GFhYUwm81WQQUAdDodDAZDk/sYDIbrtm/82pJjtuR1rnyNpixduhRarVZ6hIWFNfs1HYm0vIEDrxF1LT313nh+fMOyB8t/OIF954plroiIiNor2SeWO5P58+fDaDRKj9zcXLlLsjmzRSC3xDnPRDWaPDQMEwYGw2wReOyLDBRX1MpdEhERtUOyhaiAgAC4uLggL8/6Sqi8vDzo9fom99Hr9ddt3/i1Jcdsyetc+RpNUavV8PHxsXo4G4OpGnVmATcXBYK07nKXYxcNyx5Eo2uAJwymajy1NhMWi5C7LCIiamdkC1EqlQoxMTFISUmRtlksFqSkpCAuLq7JfeLi4qzaA0BycrLUPjIyEnq93qqNyWRCWlraNY95rdc5dOiQ1VWCycnJ8PHxQZ8+fZp9HGeUU9RwFirUzwMuSoXM1diPl9oVK6fcArWrEjtOFuDdHWfkLomIiNoZWYfz5syZg3//+9/45JNPcOzYMTz66KOoqKjA9OnTAQBTp07F/PnzpfZPPvkktmzZgtdeew3Hjx/H888/j3379uGxxx4D0HAGYfbs2ViyZAm+/fZbHDp0CFOnTkVwcDASExOl4+Tk5CAzMxM5OTkwm83IzMxEZmYmysvLAQB33XUX+vTpg4ceeggHDhzADz/8gIULF2LWrFlQq9Vt9wtqh3KKKwA41/IG19I7yAcvTmiYH/Xajyew42SBzBUREVF74irni0+cOBEFBQVISkqCwWDAwIEDsWXLFmkSd05ODpTK33Le8OHD8cUXX2DhwoVYsGABoqKisGHDBvTr109q8+yzz6KiogIzZ85EaWkpRowYgS1btkCj0UhtkpKS8Mknn0g/Dxo0CACwbds23H777XBxccHGjRvx6KOPIi4uDp6enpg2bRpefPFFe/9K2r3frsxzzqG833twcBj2Z5di7b5cPP7Ffnz72AhEBHjKXRYREbUDCiEEJ3vYiclkglarhdFodJr5UY99sR8bD17C38f2xsO3dZW7nDZRU2/GpPd3IyOnFFGBXvhm1q3wUsv6/w8iIrKj5n5+8+o8ahFnXK38RtSuLlj1PzEI9FbjVH455nCiORERgSGKWshZF9q8EZ2PBqseioHKRYkfj+bhra2n5S6JiIhkxhBFzWaqrkNJZR0A51xo80Zu6eKHJYkN8+9e/+kkvj94SeaKiIhITgxR1GyNyxt08lR12DlBDw4Jw1+GRwAAnlqXifTsEnkLIiIi2TBEUbN1xPlQTVl0Tx/E9w5Ebb0FD3+6D9lFFXKXREREMmCIombLvhyiwjvgUN6VXJQKvDlpEPqF+KC4ohbTV+9FaSVvDUNE1NEwRFGzddRJ5U3xVLviw2lDEKzV4GxBBWb+Xzpq6s1yl0VERG2IIYqajcN51nQ+Gnw0fQi81K7Yk1WMOesOwMylD4iIOgyGKGq27MsTy8MZoiS99D54939ugZuLAt8fvISk/x4G168lIuoYGKKoWerNFlworQLQMZc3uJ6RUZ3xrwcHQqEAPk/LwevJJ+UuiYiI2gBDFDXLJWM1zBYBlasSOm/NjXfoYMYPCMaLExrWkFqx9TQ+/jVL5oqIiMjeGKKoWRqH8sL83KFUKmSupn16aFg45t7ZAwDwwndH8U3GeZkrIiIie2KIombhlXnN89gfumP6rREAgKfXH8TmQ1zVnIjIWTFEUbNkFzcsKBneyVPmSto3hUKBReP64P5bQmG2CDz+ZQZ+OGKQuywiIrIDhihqFi5v0HxKpQLL/9QfEwYGo94i8NgX+/HT0Ty5yyIiIhtjiKJm4XBey7goFXjtgQG4p38Q6swC/+/z/dh2PF/usoiIyIYYouiGhBC/rRHF5Q2azdVFiTcmDsTYaD1qzRY88lk6tp9gkCIichYMUXRDxqo6lFXXAwDC/BiiWsLVRYk3Jw1CQl+ddMPiLYc5R4qIyBncVIiqrq62VR3UjjUO5XX2VsNd5SJzNY7HzUWJtybfgrHRetSZBWZ9sR8bMi7IXRYREd2kFocoi8WCf/zjHwgJCYGXlxfOnj0LAFi0aBE+/PBDmxdI8uPtXm6eylWJFZMGSVftPbUuE1+k5chdFhER3YQWh6glS5Zg9erVWL58OVQqlbS9X79++OCDD2xaHLUPnFRuG64uSrzyp/54aFg4hAAWfHMIH/x8Vu6yiIiolVocoj799FO8//77mDJlClxcfhvaGTBgAI4fP27T4qh94PIGtqNUKvDihL54ZFRXAMCS74/htR9P8KbFREQOqMUh6sKFC+jevftV2y0WC+rq6mxSFLUvvDLPthQKBZ4b00u6RcxbW09j3n8Oos5skbkyIiJqiRaHqD59+uDnn3++avtXX32FQYMG2aQoal84nGd7CoUCj4+Owj/vi4ZSAazbdx4zP92Hytp6uUsjIqJmcm3pDklJSZg2bRouXLgAi8WCr7/+GidOnMCnn36KjRs32qNGklFtvQWXjFUAgC48E2Vzf47tgs7eajz+5X5sO1GAye/vxkd/GYJOXmq5SyMiohto8ZmoCRMm4LvvvsNPP/0ET09PJCUl4dixY/juu+9w55132qNGktGF0ipYBKBxU6IzP9jt4s4+Onz+v8Pg5+GGA+eNuP/dXThXWCF3WUREdAMtPhMFACNHjkRycrKta6F26MqhPIVCIXM1zism3A9fPTocUz/cg3NFlUh851es+p8YDOvaSe7SiIjoGlp8Jqpr164oKiq6antpaSm6du1qk6Ko/fgtRHnKXInz69bZC9/8v+EYEKpFaWUd/ueDNKzdy7WkiIjaqxaHqHPnzsFsNl+1vaamBhcucBVmZ5NT1DCsxEnlbSPQR4O1j8Thnv5BqLcIzPvPIbz0/VGYLVwCgYiovWn2cN63334rff/DDz9Aq9VKP5vNZqSkpCAiIsKmxZH8fjsT5S5zJR2Hxs0Fb00ehO6BXnjjp1P4989ZOFNQgTcnDYS3xk3u8oiI6LJmh6jExEQADZdmT5s2zeo5Nzc3RERE4LXXXrNpcSS/39aI4nBeW1IoFJgd3wPdOnvh6fUHsPV4Pu57ZxfeeygG3Tp7yV0eERGhBcN5FosFFosFXbp0QX5+vvSzxWJBTU0NTpw4gXvuuceetVIbE0JwtXKZjR8QjHWPxEHno8bp/HJMePtXbDlskLssIiJCK+ZEZWVlISAgwB61UDtTXFGLilozFAog1I/DeXIZEOaLjY+PRGykP8pr6vG3z9Lx8pbjqOcK50REsmrVEgcVFRXYsWMHcnJyUFtba/XcE088YZPCSH7Zl89C6X000Li53KA12VNnbzU++99YvLz5OD74JQvvbj+Dg+dLsWLSIC7MSUQkkxaHqIyMDIwdOxaVlZWoqKiAv78/CgsL4eHhgcDAQIYoJ8KhvPbFzUWJhff0wYAwX8z7z0H8eroI49/6BW/9+RbEhPvJXR4RUYfT4uG8p556CuPHj0dJSQnc3d2xe/duZGdnIyYmBq+++qo9aiSZ5BTxnnnt0fgBwdgw61ZEBnjiorEaD76Xine2n4aFyyAQEbWpFoeozMxMzJ07F0qlEi4uLqipqUFYWBiWL1+OBQsW2KNGkknjcF44Q1S700PnjW8fuxXjBwTDbBFYvuUEpn60B/ll1XKXRkTUYbQ4RLm5uUGpbNgtMDAQOTkNKyprtVrk5ua2uICVK1ciIiICGo0GsbGx2LNnz3Xbr1+/Hr169YJGo0F0dDQ2bdpk9bwQAklJSQgKCoK7uzvi4+Nx6tQpqzbFxcWYMmUKfHx84OvrixkzZqC8vNyqzQ8//IBhw4bB29sbnTt3xv33349z5861uH+OTFojijcebpe8NW5YMWkglt/fHxo3JX45XYixb/6MHScL5C6NiKhDaHGIGjRoEPbu3QsAGDVqFJKSkvD5559j9uzZ6NevX4uOtXbtWsyZMweLFy/G/v37MWDAACQkJCA/P7/J9rt27cLkyZMxY8YMZGRkIDExEYmJiTh8+LDUZvny5VixYgVWrVqFtLQ0eHp6IiEhAdXVv/0PfcqUKThy5AiSk5OxceNG7Ny5EzNnzpSez8rKwoQJE/CHP/wBmZmZ+OGHH1BYWIg//vGPLeqfo8st5nBee6dQKPDgkDBsfHwEeum9UVhei2kf7cHSTcdQW8+r94iI7Eq00N69e8XWrVuFEELk5eWJhIQE4e3tLW655RaRkZHRomMNHTpUzJo1S/rZbDaL4OBgsXTp0ibbP/jgg2LcuHFW22JjY8UjjzwihBDCYrEIvV4vXnnlFen50tJSoVarxZdffimEEOLo0aMCgNi7d6/UZvPmzUKhUIgLFy4IIYRYv369cHV1FWazWWrz7bffCoVCIWpra5vdP6PRKAAIo9HY7H3ai6raehHx3EYRPm+jKCyrlrscaoaq2nqx8JtDInxew/t29xs7xfFLJrnLIiJyOM39/G7xmajBgwfjjjvuANAwnLdlyxaYTCakp6dj4MCBzT5ObW0t0tPTER8fL21TKpWIj49Hampqk/ukpqZatQeAhIQEqX1WVhYMBoNVG61Wi9jYWKlNamoqfH19MXjwYKlNfHw8lEol0tLSAAAxMTFQKpX4+OOPYTabYTQa8X//93+Ij4+Hm9u1b7tRU1MDk8lk9XBU50uqIATgqXKBv6dK7nKoGTRuLvhHYj+s+p8Y+Hm44eglE8a/9Qve33mG994jIrKDFoeoa9m/f3+LViwvLCyE2WyGTqez2q7T6WAwNL0is8FguG77xq83ahMYGGj1vKurK/z9/aU2kZGR+PHHH7FgwQKo1Wr4+vri/PnzWLdu3XX7tHTpUmi1WukRFhZ23fbtmTSU18kTCoVC5mqoJcb00+OHp27D6F6BqDVb8M9NxzH5/d3Se0pERLbRohD1ww8/4Omnn8aCBQtw9uxZAMDx48eRmJiIIUOGwGJxjjkYBoMBDz/8MKZNm4a9e/dix44dUKlU+NOf/gQhrv0/+vnz58NoNEqP1ky0by+yiyoA8MbDjirQW4MPpg3Gy/dHw1Plgj3nijHmjZ34ck/Odf8MExFR8zV7sc0PP/wQDz/8MPz9/VFSUoIPPvgA//rXv/D4449j4sSJOHz4MHr37t3sFw4ICICLiwvy8vKstufl5UGv1ze5j16vv277xq95eXkICgqyatM41KjX66+auF5fX4/i4mJp/5UrV0Kr1WL58uVSm88++wxhYWFIS0vDsGHDmqxPrVZDrXaO1aNziqsAcFK5I1MoFJg4pAuGdwvA3HUHsOdcMeZ/fQjfHbiIpX+M5k2liYhuUrPPRL355pt4+eWXUVhYiHXr1qGwsBDvvPMODh06hFWrVrUoQAGASqVCTEwMUlJSpG0WiwUpKSmIi4trcp+4uDir9gCQnJwstY+MjIRer7dqYzKZkJaWJrWJi4tDaWkp0tPTpTZbt26FxWJBbGwsAKCyslJaxqGRi4uLVGNHkFN8+UwUP2gdXpi/B76cOQwLx/WGxk2JXWeKkPDGTry/8wzvv0dEdDOaO1Pdw8NDZGVlCSEaroJzc3MTv/zyy03MfRdizZo1Qq1Wi9WrV4ujR4+KmTNnCl9fX2EwGIQQQjz00EPiueeek9r/+uuvwtXVVbz66qvi2LFjYvHixcLNzU0cOnRIarNs2TLh6+sr/vvf/4qDBw+KCRMmiMjISFFVVSW1GTNmjBg0aJBIS0sTv/zyi4iKihKTJ0+Wnk9JSREKhUK88MIL4uTJkyI9PV0kJCSI8PBwUVlZ2ez+OfLVeXf+a7sIn7dRbD+RL3cpZEPnCsvF5PdTpSv47lnxszh8oVTusoiI2pXmfn43O0QpFAqRl5cn/ezl5SXOnDnT+gove+utt0SXLl2ESqUSQ4cOFbt375aeGzVqlJg2bZpV+3Xr1okePXoIlUol+vbtK77//nur5y0Wi1i0aJHQ6XRCrVaL0aNHixMnTli1KSoqEpMnTxZeXl7Cx8dHTJ8+XZSVlVm1+fLLL8WgQYOEp6en6Ny5s7j33nvFsWPHWtQ3Rw1RFotF9Fy4SYTP2yjOFpTLXQ7ZmMViEWv35IjoxVtE+LyNouv878XLm4+Jqtp6uUsjImoXmvv5rRCiebNMlUollixZAi8vLwDAvHnz8MwzzyAgIMCqHW9A/BuTyQStVguj0QgfHx+5y2m2fFM1hv4zBUoFcPwfd0PlarOLOKkdyS+rxvPfHsGmQw1XpUZ08sDz9/bF7T0Db7AnEZFza+7nd7NDVERExA0vdVcoFNJVe+S4IWrfuWL8aVUqQnzd8etzf5C7HLKzH44YkPTfw8gz1QAAEvrqsOiePgj140UFRNQxNffzu9lX53W0+8Z1ZDm83UuHktBXj+HdOuHNn07h413n8MORPOw4WYDH/xCF/x0ZCbWri9wlEhG1SxynoatkFzWEqHDeeLjD8Na4YeE9fbDpiZEYGumP6joLXvnhBMa8wRsaExFdC0MUXaVxZeswnonqcHrqvbF25jC8MXEgOnurkVVYgWkf7cHDn+7D2YJyucsjImpXGKLoKo3DeTwT1TEpFAokDgpBytxR+OutkXBRKpB8NA93vb4TL353FKWVtXKXSETULjBE0VWyOSeKAPho3JA0vg+2PDkSd/TsjHqLwEe/ZmHUK9vx0S9ZqK3nQp1E1LExRJGVqlozCsoartJiiCIAiNJ54+PpQ/HpX4eip84bxqo6vLjxKBLe2Ikfjxh4Lz4i6rCafXVeI5PJ1OR2hUIBtVoNlUp100WRfHJLGs5C+Whc4evB95J+c1uPzhjerRPWp5/Haz+eQFZhBWb+XzoGh/vhmYSeiO3aSe4SiYjaVIvPRPn6+sLPz++qh6+vL9zd3REeHo7Fixd3mHvMOZvGK/O6cD4UNcHVRYnJQ7tg29O34//d3g1qVyX2ZZdg4vu7Me2jPTh8wSh3iUREbabFZ6JWr16Nv//97/jLX/6CoUOHAgD27NmDTz75BAsXLkRBQQFeffVVqNVqLFiwwOYFk31xjShqDm+NG54d0wvThkdgRcoprN2bix0nC7DjZAHu6R+EuXf1RGQAb15NRM6txSHqk08+wWuvvYYHH3xQ2jZ+/HhER0fjvffeQ0pKCrp06YKXXnqJIcoB5RRVAAC6+PMDkG5M56PBS/dF4+GRXfH6Tyfx7YGL2HjwEjYfNuDBwaF4YnQUgrTucpdJRGQXLR7O27VrFwYNGnTV9kGDBiE1NRUAMGLECOTk5Nx8ddTmeCaKWiMiwBNvThqETU+MxOhegTBbBL7ck4tRy7fj798cwoXSKrlLJCKyuRaHqLCwMHz44YdXbf/www8RFhYGACgqKoKfn9/NV0dtjiGKbkbvIB98+Jch+OpvcRjW1R+1Zgs+T8vB7a9sw/yvD0kLuRIROYMWD+e9+uqreOCBB7B582YMGTIEALBv3z4cP34cX331FQBg7969mDhxom0rJbuzWARySxrOGHChTboZgyP8sWZmHNLOFuHNlFPYdaYIX+7Jwfp9ubj/llDMuqM7L14gIoenEK1Y5CUrKwvvvfceTp48CQDo2bMnHnnkEURERNi6PofW3LtAtxeXjFWIW7oVLkoFTvxjDFxduIwY2cbec8VYkXIKP58qBAC4KBWYMDAYj47qhiidt8zVERFZa+7nd6tCFDWPo4WotLNFmPj+bnTx98DOZ++QuxxyQunZJViRcsrqpsbxvQPxyKhuGBLhL2NlRES/ae7nd4uH8wCgtLQUe/bsQX5+/lXrQU2dOrU1h6R2IJv3zCM7iwn3wyd/HYrM3FKs2n4GPxw14Kdj+fjpWD5iwv3wt1HdMLpXIJRKhdylEhHdUItD1HfffYcpU6agvLwcPj4+UCh++8dOoVAwRDmwxkm/YZxUTnY2MMwXqx6KwdmCcvz757P4T/oFpGeX4OFP96F7oBdm3tYViQNDoHLlkDIRtV8t/hdq7ty5+Otf/4ry8nKUlpaipKREehQXF9ujRmojvDKP2lrXzl5Y+sf++GXeHXj09m7w1rjidH45nv3qIEYu34qV206juKJW7jKJiJrU4hB14cIFPPHEE/Dw4Aets2m85Us4QxS1sUAfDeaN6YVdz/0BC8b2gs5HjTxTDV754QSGLU3Bs18dwLFLTd+3k4hILi0OUQkJCdi3b589aiGZcTiP5OatccPM27rh52f/gNcnDkD/UC1q6y1Yt+887n7zZ0x6PxU/HDHAbOH1MEQkvxbPiRo3bhyeeeYZHD16FNHR0XBzc7N6/t5777VZcdR2ymvqUXR52ITr95DcVK5K3DcoFIkDQ7A/pwQf/XoOWw4bsPtsMXafLUaonzumxUXgwcFh0Hq43fiARER20OIlDpTKa5+8UigUMJvNN12Us3CkJQ6OXjRh7Iqf4efhhoyku+Quh+gqF0ur8NnubHy5JwcllXUAAI2bEvf0D8aU2C4YGOZrdaELEVFr2W2Jg98vaUDOgZPKqb0L9nXHs2N64YnRUdiQcQGrd53DcUMZvko/j6/Sz6NPkA/+HNsFiYNC4KVu1eotREQtwn9pCACQU1wBAOjSyVPmSoiuT+PmgklDu2DikDDszynB52k52HjwEo5eMmHhhsNYuukY7h0YgimxXdAvRCt3uUTkxJoVolasWIGZM2dCo9FgxYoV1237xBNP2KQwalu/nYlyl7kSouZRKBSICfdHTLg/ku7pg6/Sz+OLPTk4W1CBL/fk4Ms9ORgQqsXEIV1wz4Ag+Gg4d4qIbKtZc6IiIyOxb98+dOrUCZGRkdc+mEKBs2fP2rRAR+ZIc6KmfrQHO08W4OX7ozFxSBe5yyFqFSEEdp8txudp2fjhiAF15oZ/3jRuSozpq8cDg8MQ17UTV0Qnouuy6ZyorKysJr8n55FTdHk4z5/DeeS4FAoF4rp1Qly3Tigsr8F/0s9jffp5nM4vx4bMi9iQeREhvu64PyYUD8SEcjkPIropvAGxHTnKmSizRaDnws2otwj8+twfEOLLIT1yHkIIZOaWYn36eXyXeRFlNfXSc8O6+uOBmDCM6aeHJyejE9Flzf38bnGIMpvNWL16NVJSUpq8AfHWrVtbV7ETcpQQdb6kEiNe3gY3FwWO/+NuuHCog5xUdZ0ZPxwxYP2+8/j1TCEa//Vzd3PBnX10SBwUjJFRneHmwnv2EXVkdlvi4Mknn8Tq1asxbtw49OvXj+uyOIGcy7d7CfPzYIAip6Zxc8GEgSGYMDAEF0qr8J/08/jP/vPILqrEtwcu4tsDF+Hn4YZx/YOQODAEMeF+/DeOiK6pxSFqzZo1WLduHcaOHWuPekgGObzdC3VAIb7ueGJ0FB7/Q3ccOG/EhowL2HjwIgrLa/HZ7hx8tjsHoX7uuHdAMBIHhaCHzlvukomonWlxiFKpVOjevbs9aiGZcKFN6sgUCgUGhvliYJgvFo7rjV/PFOG/mRfww2EDzpdU4Z3tZ/DO9jPoHeSDe/oHYWx0ECIDeAEGEbUiRM2dOxdvvvkm3n77bZ7mdhLZl0NUOO+ZRx2cq4sSo3p0xqgenVGVaMZPx/Lw38yL2HEyH8cumXDskgmv/HACvYN8MLafHmP7B6FbZy+5yyYimbQ4RP3yyy/Ytm0bNm/ejL59+151A+Kvv/7aZsVR28jlcB7RVdxVLhg/IBjjBwSjpKIWW44YsOnQJew6UyQFqteST6Knzhtjo4Mwrr8e3QM55EfUkbQ4RPn6+uK+++6zRy0kkxyeiSK6Lj9PFSYP7YLJQ7ugpKIWPx41YNMhA349XYgTeWU4kVeG1386iahAL4yNbhjy66Hz4tl6IifXoiUO6uvr8cUXX+Cuu+6CXq+3Z11OwRGWODBW1WHACz8CAI68kMC1cohaoLSyFslH87Dp0CX8crpQWiEdaPhPSXxvHe7so8PgcD+4ctkEIofR3M/vFv2tdnV1xd/+9jfU1NTcdIGNVq5ciYiICGg0GsTGxmLPnj3Xbb9+/Xr06tULGo0G0dHR2LRpk9XzQggkJSUhKCgI7u7uiI+Px6lTp6zaFBcXY8qUKfDx8YGvry9mzJiB8vLyq47z6quvokePHlCr1QgJCcFLL71km063I41DeQFeKgYoohby9VDhgcFh+Hj6UOz7+5147YEBGN0rECpXJbKLKvHhL1mY9P5uDHnpJ8xZl4kthy+h4orFPonIsbX4v0ZDhw5FRkaGTV587dq1mDNnDhYvXoz9+/djwIABSEhIQH5+fpPtd+3ahcmTJ2PGjBnIyMhAYmIiEhMTcfjwYanN8uXLsWLFCqxatQppaWnw9PREQkICqqurpTZTpkzBkSNHkJycjI0bN2Lnzp2YOXOm1Ws9+eST+OCDD/Dqq6/i+PHj+PbbbzF06FCb9Ls94ZV5RLah9XDD/TGh+PAvQ5Cx6E68O+UW/HFQCHw93FBSWYev91/A3z7bj0H/SMZfV+/Fl3tykF9WfeMDE1G71eIVy9etW4f58+fjqaeeQkxMDDw9rS/17d+/f7OPFRsbiyFDhuDtt98GAFgsFoSFheHxxx/Hc889d1X7iRMnoqKiAhs3bpS2DRs2DAMHDsSqVasghEBwcDDmzp2Lp59+GgBgNBqh0+mwevVqTJo0CceOHUOfPn2wd+9eDB48GACwZcsWjB07FufPn0dwcDCOHTuG/v374/Dhw+jZs2dLfj1WHGE4793tZ/DyluNIHBiMNyYNkrscIqdTb7ZgX3YJko/mIflonvQfFwBQKIABob64o2cgbu/ZGdEhWt4cmagdsNuK5ZMmTQIAPPHEE9I2hUIBIQQUCgXMZnOzjlNbW4v09HTMnz9f2qZUKhEfH4/U1NQm90lNTcWcOXOstiUkJGDDhg0AGm6ObDAYEB8fLz2v1WoRGxuL1NRUTJo0CampqfD19ZUCFADEx8dDqVQiLS0N9913H7777jt07doVGzduxJgxYyCEQHx8PJYvXw5/f/9r9qmmpsZqqNNkMjXrdyEnnokisi9XFyWGde2EYV07YeG43jiZV47kowYkH83DgfNGZOaWIjO3FK//dBKdPFUY1bMzbu8ZiNuiAuDroZK7fCK6jhaHqKysLJu8cGFhIcxmM3Q6ndV2nU6H48ePN7mPwWBosr3BYJCeb9x2vTaBgYFWz7u6usLf319qc/bsWWRnZ2P9+vX49NNPYTab8dRTT+FPf/rTde8NuHTpUrzwwgs36nq7klNcAQDo0omLBxLZm0KhQE+9N3rqvfHYH6KQZ6rG9hP52Ha8AL+cLkRRRS2+3n8BX++/AKUCuKWLH+7oFYhRPTqjb7APr/YjamdaHKLCw8PtUUe7YrFYUFNTg08//RQ9evQAAHz44YeIiYnBiRMnrjnEN3/+fKszZSaTCWFhYW1Sc2vxTBSRfHQ+Gkwc0gUTh3RBbb0F6dklDaHqRD5O5pVjX3YJ9mWX4JUfTiDQW41RPTpjZI/OuLVbJ3TyUstdPlGH1+rLsY4ePYqcnBzU1tZabb/33nubtX9AQABcXFyQl5dntT0vL++ayyfo9frrtm/8mpeXh6CgIKs2AwcOlNr8fuJ6fX09iouLpf2DgoLg6uoqBSgA6N27NwAgJyfnmiFKrVZDrXacf9jqzBZcLG2Y2MoQRSQvlasScd06Ia5bJ8wf2xsXSquks1S/ni5EflkN1qefx/r08wCAvsE+GNE9ACOiAjAkwh8aNxeZe0DU8bQ4RJ09exb33XcfDh06JM2FAiCdZm7unCiVSoWYmBikpKQgMTERQMMZoJSUFDz22GNN7hMXF4eUlBTMnj1b2pacnIy4uDgAQGRkJPR6PVJSUqTQZDKZkJaWhkcffVQ6RmlpKdLT0xETEwMA2Lp1KywWC2JjYwEAt956K+rr63HmzBl069YNAHDy5EkAznUm7mJpFcwWAbWrEoHejhP+iDqCEF93TIkNx5TYcNTUm7E3q+Es1S+nC3HcUIYjF004ctGE93aehcpViSERfhjRvTNGRgWgT5APJ6gTtYEWX503fvx4uLi44IMPPkBkZCT27NmDoqIizJ07F6+++ipGjhzZ7GOtXbsW06ZNw3vvvYehQ4fijTfewLp163D8+HHodDpMnToVISEhWLp0KYCGJQ5GjRqFZcuWYdy4cVizZg3++c9/Yv/+/ejXrx8A4OWXX8ayZcvwySefIDIyEosWLcLBgwdx9OhRaDQaAMDdd9+NvLw8rFq1CnV1dZg+fToGDx6ML774AkBDmBsyZAi8vLzwxhtvwGKxYNasWfDx8cGPP/7Y7P6196vzfj5VgIc+3IPugV74ac4oucshombKL6vGrtNF+PlUIX45XYA8k/XafX4ebhjePQAjuwdgeLcAhPm7cz4VUQvY7eq81NRUbN26FQEBAVAqlVAqlRgxYgSWLl2KJ554okVrSE2cOBEFBQVISkqCwWDAwIEDsWXLFmlieE5ODpTK35ayGj58OL744gssXLgQCxYsQFRUFDZs2CAFKAB49tlnUVFRgZkzZ6K0tBQjRozAli1bpAAFAJ9//jkee+wxjB49GkqlEvfffz9WrFghPa9UKvHdd9/h8ccfx2233QZPT0/cfffdeO2111r662rXOB+KyDEFemuQOCgEiYNCIITAmYLyhkB1qhC7zxahpLIO3x+8hO8PXgIABGs1DVcIduuEuK6deJ9MIhtp8ZkoPz8/7N+/H5GRkejWrRs++OAD3HHHHThz5gyio6NRWVl544N0EO39TNTSTcfw3s6z+MvwCDx/b1+5yyEiG6gzW5CZW4qfTxXi19OFOJBbinqL9T/zIb7ul5dd8Edct04I9WOoIrqS3c5E9evXDwcOHEBkZCRiY2OxfPlyqFQqvP/+++jatetNFU1ti2eiiJyPm4sSQyL8MSTCH3Pu7IHK2nqkZ5dg99ki7D5bjAO5pbhQWoX/7D+P/+xvmKQe6ucurWU1NMKfw39EzdTiELVw4UJUVDSsLfTiiy/innvuwciRI9GpUyesXbvW5gWS/TSGqPBODFFEzspD5YqRUZ0xMqozAKCi5spQVYSD5404X1KFr9LP46vLV/4FeqsxJMIfgyP8MCTCH7303ryBMlETWjyc15Ti4mL4+fnxfy6/056H84QQ6P/8jyirqUfyU7chSuctd0lEJIOKmnrsuxyq0s4W4dAFI+rM1h8LXmpXDOriKwWrgWG+8FDxhuXkvOw2nNfo9OnTOHPmDG677Tb4+/vDBlmM2lBpZR3KLt9NnpNMiTouT7UrRvXojFE9Gs5UVdeZcSC3FPuyS7D3XDHSz5WgrKYeP58qxM+nCgEArkoF+oZoMSTcD4Mj/HFLuC8CvTXXexkip9TiEFVUVIQHH3wQ27Ztg0KhwKlTp9C1a1fMmDEDfn5+TncFm7NqHMrT+ai5SB8RSTRuLojt2gmxXTsBAMwWgZN5Zdh3rhh7zzUEq0vGahzILcWB3FJ88EvDrcBCfN0xqIsvBnXxw6Auvugb7AO1K/9tIefW4hD11FNPwc3NDTk5OdIq3kDDcgVz5sxhiHIQ2ZxUTkTN4KJUoHeQD3oH+eChuAgAwIXSqsuhqhj7zpXgRF4ZLpRW4UJpFTZeXlZB5aJEn2Cf34JVmC9C/ThhnZxLi0PUjz/+iB9++AGhoaFW26OiopCdnW2zwsi+ci+HKA7lEVFLhfi6I2RgCCYMDAEAlFXX4dB5IzJyS5GRU4KMnFIUVdQiM7cUmbml+PjXcwCAAC/15VDli0FhfugX4gNvjZuMPSG6OS0OURUVFfDwuPqDt7i42KHuG9fRZRc1XGEZ7u8pcyVE5Oi8NQ0rpA/vHgCg4cKV3OIqZOQ2BKqMnBIcuWhCYXkNko/mIflowz1QFQqga4An+of6IjpEiwFhWvQJ0sJdxWFAcgwtDlEjR47Ep59+in/84x8AGu6ZZ7FYsHz5ctxxxx02L5DsQ1ojqpO7zJUQkbNRKBTo0skDXTp5SGerquvMOHLReDlUNQSri8ZqnCmowJmCCnyTcQEAoFQAPXTeiA7Ron+oFtGhvugd5M35VdQutThELV++HKNHj8a+fftQW1uLZ599FkeOHEFxcTF+/fVXe9RIdpBbXAWAc6KIqG1o3FwQE+6PmHB/aVtheQ0OXTDiYK4Rhy6U4sB5IwrKanDcUIbjhjKsv7xulZuLAj313ogO8W0IViFa9NR7w41rV5HMWrVOlNFoxNtvv40DBw6gvLwct9xyC2bNmoWgoCB71Oiw2us6UTX1ZvRatAVCAHv/Ho/O3hyGJaL2Ic9UjYPnjTh0viFUHbpgRHFF7VXtVC5KROm80DfYB32DtegT3DD53UvN9avo5jX389smi20CwPnz5/Hiiy/i/ffft8XhnEJ7DVFnC8rxh9d2wN3NBUdfTODVMkTUbgkhcKG0CofOG3HwgrHh6/lSmKrrm2wf0clDClV9gn3QN8gHgT5cw4paxu6Lbf5eUVERPvzwQ4YoB3DlPfMYoIioPVMoFAj180Conwfujm4Y7RBC4HxJFY5cNOLoRROOXH4YTNU4V1SJc0WV+P7QJekYAV5q9G0MVcE+6KX3QUQnD97Khm4az3t2QL9NKud8KCJyPAqFAmH+Hgjz98CYfr9NIykqr8HRSyYpWB29ZMLZgnIUltdgx8kC7DhZILVVuzYMB/bU+aCX3hu9grzRU++Nzl5q/ueSmo0hqgPKKeJCm0TkfDp5qa1utgwAlbX1OG4o+y1YXTTiZF45qurMOHzBhMMXTFbH8PdUoZe+IVA1fPVBD50X7xVITeKfig6o8UxUOM9EEZGT81C54pYufrili5+0zWIRyCmuxHGDCccNZThx+ZFVVIHiilrsOlOEXWeKpPYKBRDu73E5WDWcuYrSeSG8kyevEOzgmh2i/vjHP173+dLS0puthdpIDlcrJ6IOTKlUICLAExEBnlbDgVW1ZpzKb1he4filMpzIM+GEoQyF5bXSXKsfjuRJ7d1cFIgM8ERUoDe6B3ohSueFqEBvRAZ4QuXKcNURNDtEabXaGz4/derUmy6I7EsIYTWxnIiIGrirXNA/1Bf9Q32ttheU1eCEoQzHDQ2h6kReGU7nl6Oy1oyTeeU4mVdu1d5FqUBEJw9EBTacseoe2BCuunb25A3fnUyzQ9THH39szzqojRRV1KKy1gyFAgj142rlREQ30tlbjc7eaoyICpC2WSwCF41VOJVfjtN55TiVXyZ9X1ZTL63EvuXIb8dRKoDwTp6XQ5UXunb2QtfOnugW4AWtB+8h6Ig4J6qDyb48qTzIR8PbKBARtZJS+dvSC3f0DJS2CyFgMFXjVF55Q6jKL8OpvHKczCuDqboeWYUVyCqskO4f2KiTpwrdLoeqrp090TWg4fsu/lyKoT1jiOpgcjkfiojIbhQKBYK07gjSuuO2Hr9dJSiEQEFZDU7ll+NUXsNZq7MFFThbWI48Uw2KKmpRVFGMPeeKrY7n5qJAF38Pq7NWDUHLC/6eqrbuHv0OQ1QH03gmilfmERG1HYVCgUAfDQJ9NLi1e4DVc+U19ci6HKjO5JfjTGEFzhZUIKuwHNV1Fmlo8Pf8PNwawtXlSfIRnTwREeCB8E6evP1NG+FvuYPhpHIiovbFS+2K6FAtokOtL+CyWAQumapxtqAhXJ29HK7OFpTjorEaJZV1SM8uQXp2yVXH7OytRkSnhkAVGeCJ8E4eiOjU8NVbw/lXtsIQ1cFwOI+IyDEolQqE+LojxNfdagFRoGER0azChjNUWQUVyC6qQFZRBbKLKlFcUYuCshoUlNVg77mrA1aAl+pyoPJERCcP6SxWeIAHfBiwWoQhqoPJLm44JRzeyVPmSoiIqLU8VK7oG6xF3+Crlx8yVtUhu6gC54oqkV34W7jKLqpAYXmt9NjXxBmsTp4qdOnkgS7+DY8wfw+E+XmgSycP6H00cFHyljhXYojqQKrrzMgz1QDgcB4RkbPSurs1ud4VAJiq65BTVIlzRRU4V3g5aBVVIKuwEoXljRPca5GRU3rVvm4uDVckNgQrd+ug5e8BrXvHO4vFENWBnC9pGMrzUrvCj2uSEBF1OD4aN/QL0aJfyNVnsMpr6nGusAK5xZXIufzILalCbnElzpdUos4spCUamqJ1d5OCVaj/byGri78Hgn3dnfIWOQxRHUj2FTce5l3KiYjoSl5q12sGLLOlYf2rnKJK5JZUWget4koUltfCWFWHQxeMOHTBeNX+CgWg99E0zPHyc0eonztCfD2u+N7dIVdzZ4jqQHhlHhERtYbLFZPc49DpqucraupxvqTKKlhdGbRq6i24ZKzGJWN1k3OxgIYJ7yG+7gj1awhXDd+7S9+3x6sKGaI6EClEcY0oIiKyIU+1K3rqvdFT733Vc0IIFJbX4kJpFc6XVOJCSdXl76uk78tr6qUJ7wfOX30mCwB8NK5XBaxQP3fc3jNQtrNYDFEdSE4Rz0QREVHbUigU0v0HB4b5XvW8EALGqrqGUFXaEKwavq+UwlZpZR1M1fU4esmEo5dMVvsfev4uhiiyPw7nERFRe6NQKODroYKvh6rJ+VhAw3DhlWeyzl8OWyWVtbIO8zFEdRBCCClE8ZYvRETkSDzVruih80YP3dXDhXJyvusNqUn5ZTWoqbdAqQCCfd3lLoeIiMjhMUR1EI1noZx1rQ4iIqK2xk/TDqJxjSgO5REREdkGQ1QHwUnlREREttUuQtTKlSsREREBjUaD2NhY7Nmz57rt169fj169ekGj0SA6OhqbNm2yel4IgaSkJAQFBcHd3R3x8fE4deqUVZvi4mJMmTIFPj4+8PX1xYwZM1BeXt7k650+fRre3t7w9fW9qX7KKfdyiApjiCIiIrIJ2UPU2rVrMWfOHCxevBj79+/HgAEDkJCQgPz8/Cbb79q1C5MnT8aMGTOQkZGBxMREJCYm4vDhw1Kb5cuXY8WKFVi1ahXS0tLg6emJhIQEVFdXS22mTJmCI0eOIDk5GRs3bsTOnTsxc+bMq16vrq4OkydPxsiRI23f+TaUXdRwr6Nwf0+ZKyEiInIOCiGEkLOA2NhYDBkyBG+//TYAwGKxICwsDI8//jiee+65q9pPnDgRFRUV2Lhxo7Rt2LBhGDhwIFatWgUhBIKDgzF37lw8/fTTAACj0QidTofVq1dj0qRJOHbsGPr06YO9e/di8ODBAIAtW7Zg7NixOH/+PIKDg6Vjz5s3DxcvXsTo0aMxe/ZslJaWNrtvJpMJWq0WRqMRPj4+rfn12MzgJT+hsLwG3z02AtGhTa/DQURERM3//Jb1TFRtbS3S09MRHx8vbVMqlYiPj0dqamqT+6Smplq1B4CEhASpfVZWFgwGg1UbrVaL2NhYqU1qaip8fX2lAAUA8fHxUCqVSEtLk7Zt3boV69evx8qVK5vVn5qaGphMJqtHe1BZW4/C8hoAnBNFRERkK7KGqMLCQpjNZuh0OqvtOp0OBoOhyX0MBsN12zd+vVGbwMBAq+ddXV3h7+8vtSkqKsJf/vIXrF69utlnkZYuXQqtVis9wsLCmrWfvTVOKte6u0Hr0f5u4EhEROSIZJ8T1V49/PDD+POf/4zbbrut2fvMnz8fRqNReuTm5tqxwubjPfOIiIhsT9YQFRAQABcXF+Tl5Vltz8vLg16vb3IfvV5/3faNX2/U5vcT1+vr61FcXCy12bp1K1599VW4urrC1dUVM2bMgNFohKurKz766KMma1Or1fDx8bF6tAdc3oCIiMj2ZA1RKpUKMTExSElJkbZZLBakpKQgLi6uyX3i4uKs2gNAcnKy1D4yMhJ6vd6qjclkQlpamtQmLi4OpaWlSE9Pl9ps3boVFosFsbGxABrmTWVmZkqPF198Ed7e3sjMzMR9991nm19AG5FCFBfaJCIishnZb0A8Z84cTJs2DYMHD8bQoUPxxhtvoKKiAtOnTwcATJ06FSEhIVi6dCkA4Mknn8SoUaPw2muvYdy4cVizZg327duH999/H0DD3aBnz56NJUuWICoqCpGRkVi0aBGCg4ORmJgIAOjduzfGjBmDhx9+GKtWrUJdXR0ee+wxTJo0Sboyr3fv3lZ17tu3D0qlEv369Wuj34zt8EwUERGR7ckeoiZOnIiCggIkJSXBYDBg4MCB2LJlizQxPCcnB0rlbyfMhg8fji+++AILFy7EggULEBUVhQ0bNliFm2effRYVFRWYOXMmSktLMWLECGzZsgUajUZq8/nnn+Oxxx7D6NGjoVQqcf/992PFihVt1/E21BiiwhmiiIiIbEb2daKcWXtYJ8psEei9aAtqzRb8/OwdXLGciIjoBhxinSiyvzxTNWrNFrgqFQjSam68AxERETULQ5STaxzKC/Vzh6sL324iIiJb4aeqk2tcI4rDeERERLbFEOXkeGUeERGRfTBEObnsxivzuEYUERGRTTFEOTmeiSIiIrIPhignl1vMOVFERET2wBDlxMqq61BcUQuAZ6KIiIhsjSHKiTUO5fl7quCtcZO5GiIiIufCEOXEOJRHRERkPwxRTiy7iPfMIyIisheGKCfGK/OIiIjshyHKiUkhimtEERER2RxDlBPjmSgiIiL7YYhyUvVmCy6UVAFgiCIiIrIHhigndclYjXqLgMpFCb2PRu5yiIiInA5DlJNqHMoL9XeHUqmQuRoiIiLnwxDlpDgfioiIyL4YopwU14giIiKyL4YoJ8XVyomIiOyLIcpJcTiPiIjIvhiinFR2UQUAILyTp8yVEBEROSeGKCdkrKyDqboeABDm7y5zNURERM6JIcoJNQ7lBXip4aFylbkaIiIi58QQ5YSyixuH8jgfioiIyF4YopwQJ5UTERHZH0OUE8pliCIiIrI7hign1LjQJkMUERGR/TBEOSFpOI9zooiIiOyGIcrJ1JktuFhaBYC3fCEiIrInhignc6GkChYBqF2V6OytlrscIiIip8UQ5WSuvDJPoVDIXA0REZHzYohyMtmXQxTXiCIiIrIvhign07i8QRjnQxEREdkVQ5STyeHyBkRERG2CIcrJcDiPiIiobTBEOREhBFcrJyIiaiPtIkStXLkSERER0Gg0iI2NxZ49e67bfv369ejVqxc0Gg2io6OxadMmq+eFEEhKSkJQUBDc3d0RHx+PU6dOWbUpLi7GlClT4OPjA19fX8yYMQPl5eXS89u3b8eECRMQFBQET09PDBw4EJ9//rntOm0HJZV1KK+pBwCE+jFEERER2ZPsIWrt2rWYM2cOFi9ejP3792PAgAFISEhAfn5+k+137dqFyZMnY8aMGcjIyEBiYiISExNx+PBhqc3y5cuxYsUKrFq1CmlpafD09ERCQgKqq6ulNlOmTMGRI0eQnJyMjRs3YufOnZg5c6bV6/Tv3x//+c9/cPDgQUyfPh1Tp07Fxo0b7ffLuEnZRRUAAL2PBho3F5mrISIicnJCZkOHDhWzZs2SfjabzSI4OFgsXbq0yfYPPvigGDdunNW22NhY8cgjjwghhLBYLEKv14tXXnlFer60tFSo1Wrx5ZdfCiGEOHr0qAAg9u7dK7XZvHmzUCgU4sKFC9esdezYsWL69OnN7pvRaBQAhNFobPY+N2NDxnkRPm+jeODdXW3yekRERM6ouZ/fsp6Jqq2tRXp6OuLj46VtSqUS8fHxSE1NbXKf1NRUq/YAkJCQILXPysqCwWCwaqPVahEbGyu1SU1Nha+vLwYPHiy1iY+Ph1KpRFpa2jXrNRqN8Pf3v+bzNTU1MJlMVo+2xOUNiIiI2o6sIaqwsBBmsxk6nc5qu06ng8FgaHIfg8Fw3faNX2/UJjAw0Op5V1dX+Pv7X/N1161bh71792L69OnX7M/SpUuh1WqlR1hY2DXb2kN2Ea/MIyIiaiuyz4lyBNu2bcP06dPx73//G3379r1mu/nz58NoNEqP3NzcNqzS+pYvREREZF+yhqiAgAC4uLggLy/PanteXh70en2T++j1+uu2b/x6oza/n7heX1+P4uLiq153x44dGD9+PF5//XVMnTr1uv1Rq9Xw8fGxerQlaXkDnokiIiKyO1lDlEqlQkxMDFJSUqRtFosFKSkpiIuLa3KfuLg4q/YAkJycLLWPjIyEXq+3amMymZCWlia1iYuLQ2lpKdLT06U2W7duhcViQWxsrLRt+/btGDduHF5++WWrK/fao5p6My6ZGq4+5JkoIiIi+3OVu4A5c+Zg2rRpGDx4MIYOHYo33ngDFRUV0tyjqVOnIiQkBEuXLgUAPPnkkxg1ahRee+01jBs3DmvWrMG+ffvw/vvvAwAUCgVmz56NJUuWICoqCpGRkVi0aBGCg4ORmJgIAOjduzfGjBmDhx9+GKtWrUJdXR0ee+wxTJo0CcHBwQAahvDuuecePPnkk7j//vuluVIqleq6k8vlcr6kCkIAHioXdPJUyV0OERGR82ujqwWv66233hJdunQRKpVKDB06VOzevVt6btSoUWLatGlW7detWyd69OghVCqV6Nu3r/j++++tnrdYLGLRokVCp9MJtVotRo8eLU6cOGHVpqioSEyePFl4eXkJHx8fMX36dFFWViY9P23aNAHgqseoUaOa3a+2XOJg67E8ET5vo0h4fYfdX4uIiMiZNffzWyGEEDJmOKdmMpmg1WphNBrtPj/qk13nsPjbI7irjw7vTx184x2IiIioSc39/ObVeU6CV+YRERG1LYYoJ8E1ooiIiNoWQ5ST4GrlREREbYshygkIITicR0RE1MYYopxAQXkNqurMUCiAUD+GKCIiorbAEOUEGofygrXuULnyLSUiImoL/MR1AjnSfCh3mSshIiLqOBiinIB0ZZ6/p8yVEBERdRwMUU4ghzceJiIianMMUU4gl1fmERERtTmGKCfQOJzHEEVERNR2GKIcXFWtGfllNQAYooiIiNoSQ5SDO1/ScBbKW+MKXw83mashIiLqOBiiHNyVQ3kKhULmaoiIiDoOhigHx9u9EBERyYMhysFxeQMiIiJ5MEQ5OJ6JIiIikgdDlINjiCIiIpIHQ5QDs1iEFKJ4yxciIqK2xRDlwPLLalBbb4GLUoEgX43c5RAREXUoDFEOrPEsVLCvBm4ufCuJiIjaEj95HVh2UQUADuURERHJgSHKgTXeeDiMk8qJiIjaHEOUA5MmlXONKCIiojbHEOXAsrm8ARERkWwYohxYLkMUERGRbBiiHFRFTT0Ky2sB8JYvREREcmCIclCN86F8Pdzgo3GTuRoiIqKOhyHKQfF2L0RERPJiiHJQOUUMUURERHJiiHJQPBNFREQkL4YoB8UQRUREJC+GKAclhShemUdERCQLhigHZLYInC/hmSgiIiI5MUQ5IIOpGnVmATcXBYK07nKXQ0RE1CExRDmg7KIKAEConwdclAqZqyEiIuqYGKIcUOPtXsI4lEdERCSbdhGiVq5ciYiICGg0GsTGxmLPnj3Xbb9+/Xr06tULGo0G0dHR2LRpk9XzQggkJSUhKCgI7u7uiI+Px6lTp6zaFBcXY8qUKfDx8YGvry9mzJiB8vJyqzYHDx7EyJEjodFoEBYWhuXLl9umwzfptyvzOJRHREQkF9lD1Nq1azFnzhwsXrwY+/fvx4ABA5CQkID8/Pwm2+/atQuTJ0/GjBkzkJGRgcTERCQmJuLw4cNSm+XLl2PFihVYtWoV0tLS4OnpiYSEBFRXV0ttpkyZgiNHjiA5ORkbN27Ezp07MXPmTOl5k8mEu+66C+Hh4UhPT8crr7yC559/Hu+//779fhnNlH15oc1wf0+ZKyEiIurAhMyGDh0qZs2aJf1sNptFcHCwWLp0aZPtH3zwQTFu3DirbbGxseKRRx4RQghhsViEXq8Xr7zyivR8aWmpUKvV4ssvvxRCCHH06FEBQOzdu1dqs3nzZqFQKMSFCxeEEEK88847ws/PT9TU1Eht5s2bJ3r27NnsvhmNRgFAGI3GZu/THPe+9bMIn7dRbD50yabHJSIiouZ/fst6Jqq2thbp6emIj4+XtimVSsTHxyM1NbXJfVJTU63aA0BCQoLUPisrCwaDwaqNVqtFbGys1CY1NRW+vr4YPHiw1CY+Ph5KpRJpaWlSm9tuuw0qlcrqdU6cOIGSkpIma6upqYHJZLJ62EPjcF4414giIiKSjawhqrCwEGazGTqdzmq7TqeDwWBoch+DwXDd9o1fb9QmMDDQ6nlXV1f4+/tbtWnqGFe+xu8tXboUWq1WeoSFhTXd8ZtQVWuGyrXhbePEciIiIvnIPifKmcyfPx9Go1F65Obm2vw13FUuSFsQj+P/GAMvtavNj09ERETNI2uICggIgIuLC/Ly8qy25+XlQa/XN7mPXq+/bvvGrzdq8/uJ6/X19SguLrZq09QxrnyN31Or1fDx8bF62IvGzcVuxyYiIqIbkzVEqVQqxMTEICUlRdpmsViQkpKCuLi4JveJi4uzag8AycnJUvvIyEjo9XqrNiaTCWlpaVKbuLg4lJaWIj09XWqzdetWWCwWxMbGSm127tyJuro6q9fp2bMn/Pz8brLnRERE5PDaaKL7Na1Zs0ao1WqxevVqcfToUTFz5kzh6+srDAaDEEKIhx56SDz33HNS+19//VW4urqKV199VRw7dkwsXrxYuLm5iUOHDkltli1bJnx9fcV///tfcfDgQTFhwgQRGRkpqqqqpDZjxowRgwYNEmlpaeKXX34RUVFRYvLkydLzpaWlQqfTiYceekgcPnxYrFmzRnh4eIj33nuv2X2z19V5REREZD/N/fyWPUQJIcRbb70lunTpIlQqlRg6dKjYvXu39NyoUaPEtGnTrNqvW7dO9OjRQ6hUKtG3b1/x/fffWz1vsVjEokWLhE6nE2q1WowePVqcOHHCqk1RUZGYPHmy8PLyEj4+PmL69OmirKzMqs2BAwfEiBEjhFqtFiEhIWLZsmUt6hdDFBERkeNp7ue3Qggh5D0X5rxMJhO0Wi2MRqNd50cRERGR7TT385tX5xERERG1AkMUERERUSswRBERERG1AkMUERERUSswRBERERG1AkMUERERUSswRBERERG1AkMUERERUSswRBERERG1gqvcBTizxsXgTSaTzJUQERFRczV+bt/opi4MUXZUVlYGAAgLC5O5EiIiImqpsrIyaLXaaz7Pe+fZkcViwcWLF+Ht7Q2FQmGz45pMJoSFhSE3N9cp78nn7P0DnL+Pzt4/wPn7yP45Pmfvoz37J4RAWVkZgoODoVRee+YTz0TZkVKpRGhoqN2O7+Pj45R/MRo5e/8A5++js/cPcP4+sn+Oz9n7aK/+Xe8MVCNOLCciIiJqBYYoIiIiolZgiHJAarUaixcvhlqtlrsUu3D2/gHO30dn7x/g/H1k/xyfs/exPfSPE8uJiIiIWoFnooiIiIhagSGKiIiIqBUYooiIiIhagSGKiIiIqBUYohzQypUrERERAY1Gg9jYWOzZs0fukq7y/PPPQ6FQWD169eolPV9dXY1Zs2ahU6dO8PLywv3334+8vDyrY+Tk5GDcuHHw8PBAYGAgnnnmGdTX11u12b59O2655Rao1Wp0794dq1evtkt/du7cifHjxyM4OBgKhQIbNmywel4IgaSkJAQFBcHd3R3x8fE4deqUVZvi4mJMmTIFPj4+8PX1xYwZM1BeXm7V5uDBgxg5ciQ0Gg3CwsKwfPnyq2pZv349evXqBY1Gg+joaGzatKlN+viXv/zlqvd0zJgxDtPHpUuXYsiQIfD29kZgYCASExNx4sQJqzZt+efS1n+Pm9O/22+//ar38G9/+5tD9O/dd99F//79pYUV4+LisHnzZul5R37vmttHR37/mrJs2TIoFArMnj1b2uZw76Mgh7JmzRqhUqnERx99JI4cOSIefvhh4evrK/Ly8uQuzcrixYtF3759xaVLl6RHQUGB9Pzf/vY3ERYWJlJSUsS+ffvEsGHDxPDhw6Xn6+vrRb9+/UR8fLzIyMgQmzZtEgEBAWL+/PlSm7NnzwoPDw8xZ84ccfToUfHWW28JFxcXsWXLFpv3Z9OmTeLvf/+7+PrrrwUA8c0331g9v2zZMqHVasWGDRvEgQMHxL333isiIyNFVVWV1GbMmDFiwIABYvfu3eLnn38W3bt3F5MnT5aeNxqNQqfTiSlTpojDhw+LL7/8Uri7u4v33ntPavPrr78KFxcXsXz5cnH06FGxcOFC4ebmJg4dOmT3Pk6bNk2MGTPG6j0tLi62atOe+5iQkCA+/vhjcfjwYZGZmSnGjh0runTpIsrLy6U2bfXn0h5/j5vTv1GjRomHH37Y6j00Go0O0b9vv/1WfP/99+LkyZPixIkTYsGCBcLNzU0cPnxYCOHY711z++jI79/v7dmzR0RERIj+/fuLJ598UtruaO8jQ5SDGTp0qJg1a5b0s9lsFsHBwWLp0qUyVnW1xYsXiwEDBjT5XGlpqXBzcxPr16+Xth07dkwAEKmpqUKIhg90pVIpDAaD1Obdd98VPj4+oqamRgghxLPPPiv69u1rdeyJEyeKhIQEG/fG2u8DhsViEXq9XrzyyivSttLSUqFWq8WXX34phBDi6NGjAoDYu3ev1Gbz5s1CoVCICxcuCCGEeOedd4Sfn5/UPyGEmDdvnujZs6f084MPPijGjRtnVU9sbKx45JFH7NpHIRpC1IQJE665j6P1MT8/XwAQO3bsEEK07Z/Ltvh7/Pv+CdHwIXzlB9bvOVL/hBDCz89PfPDBB0733jXVRyGc5/0rKysTUVFRIjk52apPjvg+cjjPgdTW1iI9PR3x8fHSNqVSifj4eKSmpspYWdNOnTqF4OBgdO3aFVOmTEFOTg4AID09HXV1dVb96NWrF7p06SL1IzU1FdHR0dDpdFKbhIQEmEwmHDlyRGpz5TEa27T17yIrKwsGg8GqFq1Wi9jYWKv++Pr6YvDgwVKb+Ph4KJVKpKWlSW1uu+02qFQqqU1CQgJOnDiBkpISqY2cfd6+fTsCAwPRs2dPPProoygqKpKec7Q+Go1GAIC/vz+Atvtz2VZ/j3/fv0aff/45AgIC0K9fP8yfPx+VlZXSc47SP7PZjDVr1qCiogJxcXFO99411cdGzvD+zZo1C+PGjbuqDkd8H3kDYgdSWFgIs9ls9YcHAHQ6HY4fPy5TVU2LjY3F6tWr0bNnT1y6dAkvvPACRo4cicOHD8NgMEClUsHX19dqH51OB4PBAAAwGAxN9rPxueu1MZlMqKqqgru7u516Z62xnqZqubLWwMBAq+ddXV3h7+9v1SYyMvKqYzQ+5+fnd80+Nx7DnsaMGYM//vGPiIyMxJkzZ7BgwQLcfffdSE1NhYuLi0P10WKxYPbs2bj11lvRr18/6fXb4s9lSUmJ3f8eN9U/APjzn/+M8PBwBAcH4+DBg5g3bx5OnDiBr7/+2iH6d+jQIcTFxaG6uhpeXl745ptv0KdPH2RmZjrNe3etPgKO//4BwJo1a7B//37s3bv3qucc8e8gQxTZxd133y19379/f8TGxiI8PBzr1q1rs3BDtjVp0iTp++joaPTv3x/dunXD9u3bMXr0aBkra7lZs2bh8OHD+OWXX+QuxS6u1b+ZM2dK30dHRyMoKAijR4/GmTNn0K1bt7Yus8V69uyJzMxMGI1GfPXVV5g2bRp27Nghd1k2da0+9unTx+Hfv9zcXDz55JNITk6GRqORuxyb4HCeAwkICICLi8tVVyrk5eVBr9fLVFXz+Pr6okePHjh9+jT0ej1qa2tRWlpq1ebKfuj1+ib72fjc9dr4+Pi0aVBrrOd674ter0d+fr7V8/X19SguLrZJn+V4/7t27YqAgACcPn1aqs0R+vjYY49h48aN2LZtG0JDQ6XtbfXn0t5/j6/Vv6bExsYCgNV72J77p1Kp0L17d8TExGDp0qUYMGAA3nzzTad5767Xx6Y42vuXnp6O/Px83HLLLXB1dYWrqyt27NiBFStWwNXVFTqdzuHeR4YoB6JSqRATE4OUlBRpm8ViQUpKitWYeXtUXl6OM2fOICgoCDExMXBzc7Pqx4kTJ5CTkyP1Iy4uDocOHbL6UE5OToaPj490ajsuLs7qGI1t2vp3ERkZCb1eb1WLyWRCWlqaVX9KS0uRnp4utdm6dSssFov0D2FcXBx27tyJuro6qU1ycjJ69uwJPz8/qU176DMAnD9/HkVFRQgKCpJqa899FELgsccewzfffIOtW7deNazYVn8u7fX3+Eb9a0pmZiYAWL2H7bV/TbFYLKipqXH49645fWyKo71/o0ePxqFDh5CZmSk9Bg8ejClTpkjfO9z72KJp6CS7NWvWCLVaLVavXi2OHj0qZs6cKXx9fa2uVGgP5s6dK7Zv3y6ysrLEr7/+KuLj40VAQIDIz88XQjRcxtqlSxexdetWsW/fPhEXFyfi4uKk/RsvY73rrrtEZmam2LJli+jcuXOTl7E+88wz4tixY2LlypV2W+KgrKxMZGRkiIyMDAFA/Otf/xIZGRkiOztbCNGwxIGvr6/473//Kw4ePCgmTJjQ5BIHgwYNEmlpaeKXX34RUVFRVpf/l5aWCp1OJx566CFx+PBhsWbNGuHh4XHV5f+urq7i1VdfFceOHROLFy+22RIH1+tjWVmZePrpp0VqaqrIysoSP/30k7jllltEVFSUqK6udog+Pvroo0Kr1Yrt27dbXSJeWVkptWmrP5f2+Ht8o/6dPn1avPjii2Lfvn0iKytL/Pe//xVdu3YVt912m0P077nnnhM7duwQWVlZ4uDBg+K5554TCoVC/Pjjj0IIx37vmtNHR3//ruX3Vxw62vvIEOWA3nrrLdGlSxehUqnE0KFDxe7du+Uu6SoTJ04UQUFBQqVSiZCQEDFx4kRx+vRp6fmqqirx//7f/xN+fn7Cw8ND3HfffeLSpUtWxzh37py4++67hbu7uwgICBBz584VdXV1Vm22bdsmBg4cKFQqlejatav4+OOP7dKfbdu2CQBXPaZNmyaEaFjmYNGiRUKn0wm1Wi1Gjx4tTpw4YXWMoqIiMXnyZOHl5SV8fHzE9OnTRVlZmVWbAwcOiBEjRgi1Wi1CQkLEsmXLrqpl3bp1okePHkKlUom+ffuK77//3u59rKysFHfddZfo3LmzcHNzE+Hh4eLhhx++6h+c9tzHpvoGwOrPTFv+ubT13+Mb9S8nJ0fcdtttwt/fX6jVatG9e3fxzDPPWK0z1J7799e//lWEh4cLlUolOnfuLEaPHi0FKCEc+71rTh8d/f27lt+HKEd7HxVCCNGyc1dERERExDlRRERERK3AEEVERETUCgxRRERERK3AEEVERETUCgxRRERERK3AEEVERETUCgxRRERERK3AEEVERETUCgxRREQAIiIi8MYbb8hdBhE5EIYoInIoCoXiuo/nn3++Vcfdu3cvZs6ceVO1ZWVl4c9//jOCg4Oh0WgQGhqKCRMm4Pjx4wCAc+fOQaFQSDeOJSLH5ip3AURELXHp0iXp+7Vr1yIpKQknTpyQtnl5eUnfCyFgNpvh6nrjf+o6d+58U3XV1dXhzjvvRM+ePfH1118jKCgI58+fx+bNm1FaWnpTxyai9olnoojIoej1eumh1WqhUCikn48fPw5vb29s3rwZMTExUKvV+OWXX3DmzBlMmDABOp0OXl5eGDJkCH766Ser4/5+OE+hUOCDDz7AfffdBw8PD0RFReHbb7+9Zl1HjhzBmTNn8M4772DYsGEIDw/HrbfeiiVLlmDYsGEAgMjISADAoEGDoFAocPvtt0v7f/DBB+jduzc0Gg169eqFd955R3qu8QzWmjVrMHz4cGg0GvTr1w87duywwW+UiFqLIYqInM5zzz2HZcuW4dixY+jfvz/Ky8sxduxYpKSkICMjA2PGjMH48eORk5Nz3eO88MILePDBB3Hw4EGMHTsWU6ZMQXFxcZNtO3fuDKVSia+++gpms7nJNnv27AEA/PTTT7h06RK+/vprAMDnn3+OpKQkvPTSSzh27Bj++c9/YtGiRfjkk0+s9n/mmWcwd+5cZGRkIC4uDuPHj0dRUVFLfz1EZCuCiMhBffzxx0Kr1Uo/b9u2TQAQGzZsuOG+ffv2FW+99Zb0c3h4uHj99delnwGIhQsXSj+Xl5cLAGLz5s3XPObbb78tPDw8hLe3t7jjjjvEiy++KM6cOSM9n5WVJQCIjIwMq/26desmvvjiC6tt//jHP0RcXJzVfsuWLZOer6urE6GhoeLll1++YV+JyD54JoqInM7gwYOtfi4vL8fTTz+N3r17w9fXF15eXjh27NgNz0T1799f+t7T0xM+Pj7Iz8+/ZvtZs2bBYDDg888/R1xcHNavX4++ffsiOTn5mvtUVFTgzJkzmDFjBry8vKTHkiVLcObMGau2cXFx0veurq4YPHgwjh07dt0+EJH9cGI5ETkdT09Pq5+ffvppJCcn49VXX0X37t3h7u6OP/3pT6itrb3ucdzc3Kx+VigUsFgs193H29sb48ePx/jx47FkyRIkJCRgyZIluPPOO5tsX15eDgD497//jdjYWKvnXFxcrvtaRCQvnokiIqf366+/4i9/+Qvuu+8+REdHQ6/X49y5c3Z/XYVCgV69eqGiogIAoFKpAMBqzpROp0NwcDDOnj2L7t27Wz0aJ6I32r17t/R9fX090tPT0bt3b7v3g4iaxjNRROT0oqKi8PXXX2P8+PFQKBRYtGjRDc8otVRmZiYWL16Mhx56CH369IFKpcKOHTvw0UcfYd68eQCAwMBAuLu7Y8uWLQgNDYVGo4FWq8ULL7yAJ554AlqtFmPGjEFNTQ327duHkpISzJkzR3qNlStXIioqCr1798brr7+OkpIS/PWvf7VpP4io+RiiiMjp/etf/8Jf//pXDB8+HAEBAZg3bx5MJpNNXyM0NBQRERF44YUXpCUJGn9+6qmnADTMY1qxYgVefPFFJCUlYeTIkdi+fTv+93//Fx4eHnjllVfwzDPPwNPTE9HR0Zg9e7bVayxbtgzLli1DZmYmunfvjm+//RYBAQE27QcRNZ9CCCHkLoKIiK7t3LlziIyMREZGBgYOHCh3OUR0GedEEREREbUCQxQRERFRK3A4j4iIiKgVeCaKiIiIqBUYooiIiIhagSGKiIiIqBUYooiIiIhagSGKiIiIqBUYooiIiIhagSGKiIiIqBUYooiIiIha4f8D1K7jBc0D1zkAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning_rate(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c77c17-5e5f-40b8-ad5b-8654da4cf873",
   "metadata": {},
   "source": [
    "## Setup loss and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572d709e-324f-473a-9779-8ad2fb2ad38e",
   "metadata": {},
   "source": [
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss. Use the cross-entropy loss function (`tf.keras.losses.SparseCategoricalCrossentropy`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7be20d9-a128-4fa3-a3d4-3510c1a34cba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def masked_loss(label, pred):\n",
    "  mask = label != 0\n",
    "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "  loss = loss_object(label, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss.dtype)\n",
    "  loss *= mask\n",
    "\n",
    "  loss = tf.reduce_sum(loss)/tf.reduce_sum(mask)\n",
    "  return loss\n",
    "\n",
    "\n",
    "def masked_accuracy(label, pred):\n",
    "  pred = tf.argmax(pred, axis=2)\n",
    "  label = tf.cast(label, pred.dtype)\n",
    "  match = label == pred\n",
    "\n",
    "  mask = label != 0\n",
    "\n",
    "  match = match & mask\n",
    "\n",
    "  match = tf.cast(match, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(match)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3e8b0-1058-49c9-913f-85b8b5b512c5",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c4fa516a-70f8-4330-b6c4-7e56f617e9bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer.compile(\n",
    "    loss=masked_loss,\n",
    "    optimizer=optimizer,\n",
    "    metrics=[masked_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1035ad46-c9b9-496c-8a5d-ed2f02561be7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "810/810 [==============================] - ETA: 0s - loss: 6.4903 - masked_accuracy: 0.1469"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 12:36:12.316429: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_36' with dtype int64\n",
      "\t [[{{node Placeholder/_36}}]]\n",
      "2023-06-26 12:36:12.317322: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_32' with dtype int64\n",
      "\t [[{{node Placeholder/_32}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "810/810 [==============================] - 4627s 6s/step - loss: 6.4903 - masked_accuracy: 0.1469 - val_loss: 4.9886 - val_masked_accuracy: 0.2570\n",
      "Epoch 2/3\n",
      "810/810 [==============================] - 5018s 6s/step - loss: 4.5243 - masked_accuracy: 0.3048 - val_loss: 4.0008 - val_masked_accuracy: 0.3677\n",
      "Epoch 3/3\n",
      "810/810 [==============================] - 4713s 6s/step - loss: 3.7857 - masked_accuracy: 0.3848 - val_loss: 3.3732 - val_masked_accuracy: 0.4419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd586fc8400>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer.fit(train_batches,\n",
    "                epochs=3,\n",
    "                validation_data=val_batches)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f132f41c-d26f-469c-b8bf-8229f00ab497",
   "metadata": {},
   "source": [
    "# Run inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94016fcc-8574-41b2-a65c-eea6f6d54f50",
   "metadata": {},
   "source": [
    "You can now test the model by performing a translation. The following steps are used for inference:\n",
    "\n",
    "* Encode the input sentence using the Portuguese tokenizer (`tokenizers.pt`). This is the encoder input.\n",
    "* The decoder input is initialized to the `[START]` token.\n",
    "* Calculate the padding masks and the look ahead masks.\n",
    "* The `decoder` then outputs the predictions by looking at the `encoder output` and its own output (self-attention).\n",
    "* Concatenate the predicted token to the decoder input and pass it to the decoder.\n",
    "* In this approach, the decoder predicts the next token based on the previous tokens it predicted.\n",
    "\n",
    "Note: The model is optimized for _efficient training_ and makes a next-token prediction for each token in the output simultaneously. This is redundant during inference, and only the last prediction is used.  This model can be made more efficient for inference if you only calculate the last prediction when running in inference mode (`training=False`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "197b2bda-0439-4d4d-b0d3-c46a8afec0ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Translator(tf.Module):\n",
    "  def __init__(self, tokenizers, transformer):\n",
    "    self.tokenizers = tokenizers\n",
    "    self.transformer = transformer\n",
    "\n",
    "  def __call__(self, sentence, max_length=MAX_TOKENS):\n",
    "    # The input sentence is Portuguese, hence adding the `[START]` and `[END]` tokens.\n",
    "    assert isinstance(sentence, tf.Tensor)\n",
    "    if len(sentence.shape) == 0:\n",
    "      sentence = sentence[tf.newaxis]\n",
    "\n",
    "    sentence = self.tokenizers.pt.tokenize(sentence).to_tensor()\n",
    "\n",
    "    encoder_input = sentence\n",
    "\n",
    "    # As the output language is English, initialize the output with the\n",
    "    # English `[START]` token.\n",
    "    start_end = self.tokenizers.en.tokenize([''])[0]\n",
    "    start = start_end[0][tf.newaxis]\n",
    "    end = start_end[1][tf.newaxis]\n",
    "\n",
    "    # `tf.TensorArray` is required here (instead of a Python list), so that the\n",
    "    # dynamic-loop can be traced by `tf.function`.\n",
    "    output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
    "    output_array = output_array.write(0, start)\n",
    "\n",
    "    for i in tf.range(max_length):\n",
    "      output = tf.transpose(output_array.stack())\n",
    "      predictions = self.transformer([encoder_input, output], training=False)\n",
    "\n",
    "      # Select the last token from the `seq_len` dimension.\n",
    "      predictions = predictions[:, -1:, :]  # Shape `(batch_size, 1, vocab_size)`.\n",
    "\n",
    "      predicted_id = tf.argmax(predictions, axis=-1)\n",
    "\n",
    "      # Concatenate the `predicted_id` to the output which is given to the\n",
    "      # decoder as its input.\n",
    "      output_array = output_array.write(i+1, predicted_id[0])\n",
    "\n",
    "      if predicted_id == end:\n",
    "        break\n",
    "\n",
    "    output = tf.transpose(output_array.stack())\n",
    "    # The output shape is `(1, tokens)`.\n",
    "    text = tokenizers.en.detokenize(output)[0]  # Shape: `()`.\n",
    "\n",
    "    tokens = tokenizers.en.lookup(output)[0]\n",
    "\n",
    "    # `tf.function` prevents us from using the attention_weights that were\n",
    "    # calculated on the last iteration of the loop.\n",
    "    # So, recalculate them outside the loop.\n",
    "    self.transformer([encoder_input, output[:,:-1]], training=False)\n",
    "    attention_weights = self.transformer.decoder.last_attn_scores\n",
    "\n",
    "    return text, tokens, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "078fce63-8e1a-4ad5-b1b7-d26e1681710c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_translation(sentence, tokens, ground_truth):\n",
    "  print(f'{\"Input:\":15s}: {sentence}')\n",
    "  print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}')\n",
    "  print(f'{\"Ground truth\":15s}: {ground_truth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1fd173d-904e-482f-9a0d-693e47c7d91d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(seq, truth):\n",
    "    \n",
    "    translated_seq, translated_tokens, attention_weights = translator(\n",
    "    tf.constant(seq))\n",
    "    print_translation(seq, translated_seq, truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5defa03a-2b7c-4b12-9551-ee3469b4fb72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "translator = Translator(tokenizers, transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ef541061-e5e0-49a7-80db-2a09748dba07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:         : este é um problema que temos que resolver.\n",
      "Prediction     : this is a problem that we have to try .\n",
      "Ground truth   : this is a problem we have to solve .\n"
     ]
    }
   ],
   "source": [
    "sentence = 'este é um problema que temos que resolver.'\n",
    "ground_truth = 'this is a problem we have to solve .'\n",
    "\n",
    "translate(sentence, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eedfed1-8c82-4f31-a56b-c65e01ce6a2f",
   "metadata": {},
   "source": [
    "# Export the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4b090-c457-4389-a9e9-49291eede067",
   "metadata": {},
   "source": [
    "Create a class called `ExportTranslator` by subclassing the `tf.Module` subclass with a `tf.function` on the `__call__` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "44d5f931-0f0c-48ad-93cd-0db622f83045",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ExportTranslator(tf.Module):\n",
    "  def __init__(self, translator):\n",
    "    self.translator = translator\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])\n",
    "  def __call__(self, sentence):\n",
    "    (result,\n",
    "     tokens,\n",
    "     attention_weights) = self.translator(sentence, max_length=MAX_TOKENS)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b8427947-578d-4e15-adaf-e4b124af1a06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "translator = ExportTranslator(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdb87230-a2f1-472f-886d-c52698cec3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 15:56:11.164947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tokenized' with dtype int64 and shape [1,?]\n",
      "\t [[{{node tokenized}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'this is the first book i did .'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator('este é o primeiro livro que eu fiz.').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a28694ab-9131-42f8-ad61-75dd650fa618",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 15:56:22.307008: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'tokenized' with dtype int64 and shape [1,?]\n",
      "\t [[{{node tokenized}}]]\n",
      "2023-06-26 15:56:23.601787: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '102195' with dtype float and shape [2048,128]\n",
      "\t [[{{node 102195}}]]\n",
      "2023-06-26 15:56:24.915172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_18_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_18_input}}]]\n",
      "2023-06-26 15:56:24.949808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_18_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_18_input}}]]\n",
      "2023-06-26 15:56:24.965668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:24.975885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_18_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_18_input}}]]\n",
      "2023-06-26 15:56:24.984801: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:24.995334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_18_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_18_input}}]]\n",
      "2023-06-26 15:56:25.002050: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.008583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.014965: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.029956: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.038632: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.097055: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_20_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_20_input}}]]\n",
      "2023-06-26 15:56:25.134214: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_20_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_20_input}}]]\n",
      "2023-06-26 15:56:25.151316: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.163414: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_20_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_20_input}}]]\n",
      "2023-06-26 15:56:25.172913: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.182745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_20_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_20_input}}]]\n",
      "2023-06-26 15:56:25.190533: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.197307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.203425: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.218552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.228613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.291145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_22_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_22_input}}]]\n",
      "2023-06-26 15:56:25.332309: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_22_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_22_input}}]]\n",
      "2023-06-26 15:56:25.352501: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.365745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_22_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_22_input}}]]\n",
      "2023-06-26 15:56:25.375420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.386410: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_22_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_22_input}}]]\n",
      "2023-06-26 15:56:25.394172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.401868: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.409009: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.425821: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.435323: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.849552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_24_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_24_input}}]]\n",
      "2023-06-26 15:56:25.891758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_24_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_24_input}}]]\n",
      "2023-06-26 15:56:25.908487: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.920131: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_24_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_24_input}}]]\n",
      "2023-06-26 15:56:25.929961: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.941683: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_24_input' with dtype float and shape [?,67,128]\n",
      "\t [[{{node dense_24_input}}]]\n",
      "2023-06-26 15:56:25.948941: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.955969: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.962453: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.978156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:25.987797: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.076371: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_26_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_26_input}}]]\n",
      "2023-06-26 15:56:26.120590: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_26_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_26_input}}]]\n",
      "2023-06-26 15:56:26.142012: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.152072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_26_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_26_input}}]]\n",
      "2023-06-26 15:56:26.162885: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.174813: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_26_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_26_input}}]]\n",
      "2023-06-26 15:56:26.181297: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.188546: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.195167: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.210475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.219300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.300620: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-06-26 15:56:26.348068: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-06-26 15:56:26.365179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.378729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-06-26 15:56:26.388611: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.402639: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_28_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_28_input}}]]\n",
      "2023-06-26 15:56:26.412707: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.419442: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.426220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.441335: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.450156: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.522187: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_30_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_30_input}}]]\n",
      "2023-06-26 15:56:26.560199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_30_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_30_input}}]]\n",
      "2023-06-26 15:56:26.578172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.589587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_30_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_30_input}}]]\n",
      "2023-06-26 15:56:26.599552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.612277: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_30_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_30_input}}]]\n",
      "2023-06-26 15:56:26.619626: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.627855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.634387: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.651088: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.662707: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.744191: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_32_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_32_input}}]]\n",
      "2023-06-26 15:56:26.785304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_32_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_32_input}}]]\n",
      "2023-06-26 15:56:26.805118: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.818834: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_32_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_32_input}}]]\n",
      "2023-06-26 15:56:26.830855: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.844863: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'dense_32_input' with dtype float and shape [?,72,128]\n",
      "\t [[{{node dense_32_input}}]]\n",
      "2023-06-26 15:56:26.852840: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.861552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.870307: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.887154: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:26.898045: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:27.458150: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'encoder_1/107438' with dtype float and shape [2048,128]\n",
      "\t [[{{node encoder_1/107438}}]]\n",
      "2023-06-26 15:56:28.319613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_1/108990' with dtype float and shape [2048,128]\n",
      "\t [[{{node decoder_1/108990}}]]\n",
      "2023-06-26 15:56:29.824981: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'encoder_1/111809' with dtype float and shape [2048,128]\n",
      "\t [[{{node encoder_1/111809}}]]\n",
      "2023-06-26 15:56:29.886552: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'decoder_1/111942' with dtype float and shape [2048,128]\n",
      "\t [[{{node decoder_1/111942}}]]\n",
      "2023-06-26 15:56:30.022581: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '112162' with dtype float and shape [2048,128]\n",
      "\t [[{{node 112162}}]]\n",
      "2023-06-26 15:56:30.022754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '112294' with dtype float and shape [2048,128]\n",
      "\t [[{{node 112294}}]]\n",
      "2023-06-26 15:56:30.315526: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '113226' with dtype float and shape [2048,128]\n",
      "\t [[{{node 113226}}]]\n",
      "2023-06-26 15:56:30.436785: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '113502' with dtype float and shape [2048,128]\n",
      "\t [[{{node 113502}}]]\n",
      "2023-06-26 15:56:30.529950: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:30.669534: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '113948' with dtype float and shape [2048,128]\n",
      "\t [[{{node 113948}}]]\n",
      "2023-06-26 15:56:30.669789: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '114080' with dtype float and shape [2048,128]\n",
      "\t [[{{node 114080}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "2023-06-26 15:56:30.982122: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '114656' with dtype float and shape [2048,128]\n",
      "\t [[{{node 114656}}]]\n",
      "2023-06-26 15:56:30.982343: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '114788' with dtype float and shape [2048,128]\n",
      "\t [[{{node 114788}}]]\n",
      "2023-06-26 15:56:33.594205: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '120051' with dtype float and shape [2048,128]\n",
      "\t [[{{node 120051}}]]\n",
      "2023-06-26 15:56:34.515907: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '122145' with dtype float and shape [2048,128]\n",
      "\t [[{{node 122145}}]]\n",
      "2023-06-26 15:56:35.801463: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.187166: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.196411: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.299421: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.309062: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.410390: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.422296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.530403: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.539440: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.664466: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.675124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.793460: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.801677: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.922039: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:36.931710: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.050600: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.059478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.541248: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.566862: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.593384: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.621763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.649000: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.676909: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.709515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.736127: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.766278: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.799741: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.826411: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.854220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,67,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.895238: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.923398: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.951003: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:37.988594: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:38.016679: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:38.044260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:38.083663: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:38.116027: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:38.144795: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:38.178402: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:38.205755: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,512]\n",
      "\t [[{{node inputs}}]]\n",
      "2023-06-26 15:56:38.233996: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'inputs' with dtype float and shape [?,72,128]\n",
      "\t [[{{node inputs}}]]\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, positional_embedding_4_layer_call_fn, positional_embedding_4_layer_call_and_return_conditional_losses, dropout_30_layer_call_fn, dropout_30_layer_call_and_return_conditional_losses while saving (showing 5 of 317). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: translator/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(translator, export_dir='translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6bec9be-4814-4ae5-8be7-cb2308695878",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reloaded = tf.saved_model.load('translator')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "31284c9a-f9a3-4735-b2bb-d97b4ac26dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-26 15:57:01.537725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor '172780' with dtype float and shape [2048,128]\n",
      "\t [[{{node 172780}}]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'this is the first book i did .'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded('este é o primeiro livro que eu fiz.').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d86d431-a3b8-420e-8d12-e4979d8ab077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
